{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h7eobM5PgUx"
      },
      "source": [
        "Some really important papers and sites that assisted us.\n",
        "\n",
        "\n",
        "**Credit must be given where it is due !**\n",
        "\n",
        "\n",
        "*   https://lilianweng.github.io/posts/2020-10-29-odqa/#open-book-qa-retriever-generator\n",
        "\n",
        "*   https://dev.to/ksk0629/my-own-chatbot-by-fine-tuning-gpt-2-m0n\n",
        "\n",
        "* https://omarito.me/building-a-seq2seq-conversational-chat-bot-using-tensorflow/\n",
        "\n",
        "* https://suriyadeepan.github.io/2016-06-28-easy-seq2seq/\n",
        "\n",
        "* https://towardsdatascience.com/generative-chatbots-using-the-seq2seq-model-d411c8738ab5\n",
        "\n",
        "* https://github.com/Marsan-Ma-zz/tf_chatbot_seq2seq_antilm\n",
        "\n",
        "* https://github.com/minimaxir/gpt-2-simple\n",
        "\n",
        "* https://github.com/ksk0629/chatbot_with_gpt2\n",
        "\n",
        "* https://github.com/Conchylicultor/DeepQA/blob/master/chatbot/model.py\n",
        "\n",
        "* https://github.com/UraliRana/Chatbot/blob/master/chatbot(Luong%20attention)small%20dataset/Untitled%20show.ipynb\n",
        "\n",
        "* https://www.kaggle.com/code/jonathanbesomi/question-answering-starter-pack\n",
        "\n",
        "* https://www.kaggle.com/code/thedrcat/question-answering-tutorial\n",
        "\n",
        "* https://docs.aitextgen.io/gpt-2-simple/\n",
        "\n",
        "* https://colab.research.google.com/github/gradio-app/gradio/blob/main/demo/text_generation/run.ipynb#scrollTo=2.8891853944186117e%2B38\n",
        "\n",
        "* https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn2NhdYQVPvv"
      },
      "source": [
        "#Imports&Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KtBNDulOL_z",
        "outputId": "2d14d5b4-6e95-4603-a25a-808038a753e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gpt-2-simple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyXLou4oVMHq"
      },
      "outputs": [],
      "source": [
        "# Miscellaneous\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# NLP\n",
        "import re\n",
        "import string\n",
        "\n",
        "# For Modeling DL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, LSTM, Bidirectional, Embedding, Concatenate, Layer\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Input, Model\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "# for GPT-2\n",
        "import gpt_2_simple as gpt2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfqQvJ7rWXde",
        "outputId": "3f5ea876-86fc-44f4-d714-6057089937c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1x7oymReme0U8czQHuft_EKN-dWm-2le4\n",
            "To: /content/NLP_Data.csv\n",
            "\r  0% 0.00/5.72M [00:00<?, ?B/s]\r100% 5.72M/5.72M [00:00<00:00, 197MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown \"1x7oymReme0U8czQHuft_EKN-dWm-2le4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhPX0cWXcQ_Y",
        "outputId": "db13f3c0-7bc2-41fe-caad-ed45fa35d652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 310Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:01, 626kit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 135Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:25, 5.80Mit/s]\n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 526Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:01, 841kit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:01, 841kit/s]\n"
          ]
        }
      ],
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjIsst-_VQGG"
      },
      "source": [
        "#Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VjLocuMVQYX"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/NLP_Data.csv\", index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Hp2oLn1fXlVh",
        "outputId": "387efdcd-c446-4b8c-b001-c1cb5d736dc7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5590d814-a316-4c1b-883e-4ff97f0000d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How can I keep my cat off my keyboard?</td>\n",
              "      <td>\\nPlace a box near your keyboard that is the r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How can I keep my cat off my keyboard?</td>\n",
              "      <td>This happens because my cat likes to sit on my...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I keep my cat off my keyboard?</td>\n",
              "      <td>I remember this from /r/funny a while back - a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can I keep my cat off my keyboard?</td>\n",
              "      <td>Animals need boundaries. The only way to preve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>How can I keep my cat off my keyboard?</td>\n",
              "      <td>The floating judgement box should work - I gue...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5590d814-a316-4c1b-883e-4ff97f0000d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5590d814-a316-4c1b-883e-4ff97f0000d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5590d814-a316-4c1b-883e-4ff97f0000d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                 Question  \\\n",
              "0  How can I keep my cat off my keyboard?   \n",
              "1  How can I keep my cat off my keyboard?   \n",
              "2  How can I keep my cat off my keyboard?   \n",
              "3  How can I keep my cat off my keyboard?   \n",
              "4  How can I keep my cat off my keyboard?   \n",
              "\n",
              "                                              Answer  \n",
              "0  \\nPlace a box near your keyboard that is the r...  \n",
              "1  This happens because my cat likes to sit on my...  \n",
              "2  I remember this from /r/funny a while back - a...  \n",
              "3  Animals need boundaries. The only way to preve...  \n",
              "4  The floating judgement box should work - I gue...  "
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-J-vH7rGXyxH"
      },
      "outputs": [],
      "source": [
        "Qs = df['Question']\n",
        "As = df['Answer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_g7rDX0Yrxk"
      },
      "outputs": [],
      "source": [
        "# split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(As, Qs,test_size=0.05, shuffle = True, random_state = 8)\n",
        "\n",
        "# split into train and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,test_size=0.2, shuffle = True, random_state = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVpsiAbHVRBt"
      },
      "outputs": [],
      "source": [
        "startMark = '<start>'\n",
        "endMark = '<end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUvIZqh5dtRy"
      },
      "outputs": [],
      "source": [
        "def cleanText(text):\n",
        "    # strip whitespaces and lowercase\n",
        "    text = text.strip(' ').lower()\n",
        "    text = re.sub(r'[^A-Za-z]', ' ', text)\n",
        "    text = text.lower().strip()\n",
        "    text = \" \".join([word for word in text.split(\" \") if word])\n",
        "    return startMark+\" \"+text+\" \"+endMark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-P8xBooueu9R",
        "outputId": "5356232e-7c7d-4433-d0e8-c91b56ebf4b1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Take a sip of water and swish it around in your mouth in the same way you would a fluoride rinse. This will push out most particles.\\nI've used -- although it may not be the best idea -- a bent paperclip. It works essentially the same as a toothpick, but is metal, so it can hurt your gums if you're not careful. Use the bathroom mirror if possible.\""
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "As[511]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ooOMjT39n2YW",
        "outputId": "a8deb3bc-39f2-45ce-aa79-ce2414988a14"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> take a sip of water and swish it around in your mouth in the same way you would a fluoride rinse this will push out most particles i ve used although it may not be the best idea a bent paperclip it works essentially the same as a toothpick but is metal so it can hurt your gums if you re not careful use the bathroom mirror if possible <end>'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cleanText(As[511])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXYoL-9mVeMN"
      },
      "source": [
        "#Trial-1\n",
        "Seq2Seq Model Inspired By the following [medium](https://medium.com/geekculture/neural-machine-translation-using-seq2seq-model-with-attention-9faea357d70b) article about MT made with a custom attention layer.\n",
        "\n",
        "\n",
        "Even though this is what we call the copy-pasta attempt, We learned some things from it nonetheless."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Architecture"
      ],
      "metadata": {
        "id": "i_nBSaR75Fk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUqqnGy0OcjK"
      },
      "outputs": [],
      "source": [
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "     \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\n",
        "            if verbose:\n",
        "                print('wa.s>',W_a_dot_s.shape)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>',U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', reshaped_Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        def create_inital_state(inputs, hidden_size):\n",
        "            # We are not using initial states, but need to pass something to K.rnn funciton\n",
        "            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\n",
        "            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\n",
        "            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\n",
        "            return fake_state\n",
        "\n",
        "        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\n",
        "        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IpoAwG6rc89"
      },
      "outputs": [],
      "source": [
        "# adding special tokens and cleaning the text\n",
        "df.Answer = df.Answer.apply(lambda x: cleanText(str(x)))\n",
        "\n",
        "# Convert into list of sentence we need list to pass in tokenizer\n",
        "Qs = df.Question.to_list()\n",
        "As = df.Answer.to_list()\n",
        "\n",
        "# Tokenize senteces with simple fuction\n",
        "def tokenize_sent(text):\n",
        "  '''\n",
        "  Take list on texts as input and\n",
        "  returns its tokenizer and enocoded text\n",
        "  '''\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(text)\n",
        "\n",
        "  return tokenizer, tokenizer.texts_to_sequences(text)\n",
        "\n",
        "\n",
        "# Tokenize question and answer sentences\n",
        "Qs_tokenizer, Qs_encoded = tokenize_sent(text = Qs)\n",
        "As_tokenizer, As_encoded = tokenize_sent(text = As)\n",
        "\n",
        "# Question Word --> index dictionary\n",
        "Qs_index_word = Qs_tokenizer.index_word\n",
        "\n",
        "# Question Index --> word dictionary\n",
        "Qs_word_index= As_tokenizer.word_index\n",
        "\n",
        "# size of Question vocabulary for encoder input we add +1 for the zero padding\n",
        "Qs_VOCAB_SIZE = len(Qs_tokenizer.word_counts)+1\n",
        "\n",
        "# Answer Word --> index dict\n",
        "As_word_index= As_tokenizer.word_index\n",
        "\n",
        "# Answer Index --> word dict\n",
        "As_index_word = As_tokenizer.index_word\n",
        "\n",
        "# Answer vocab size for decoder output\n",
        "As_VOCAB_SIZE=len(As_tokenizer.word_counts)+1\n",
        "\n",
        "# Getting max length of Question and Answer sentences\n",
        "max_Q_len = 0\n",
        "for i in range(len(Qs_encoded)):\n",
        "  max_Q_len= max(max_Q_len, len(Qs_encoded[i]))\n",
        "\n",
        "max_A_len = 0\n",
        "for i in range(len(As_encoded)):\n",
        "  max_A_len= max(max_A_len, len(As_encoded[i]))\n",
        "\n",
        "# Padding both\n",
        "Qs_padded = pad_sequences(Qs_encoded, maxlen=max_Q_len, padding='post')\n",
        "As_padded = pad_sequences(As_encoded, maxlen=max_A_len, padding='post')\n",
        "\n",
        "# Convert to array\n",
        "Qs_padded= np.array(Qs_padded)\n",
        "As_padded= np.array(As_padded)\n",
        "\n",
        "# Split data into train and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(Qs_padded, As_padded, test_size=0.01, shuffle = True, random_state = 8)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle = True, random_state = 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA9TeyMSrY13"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = Input(shape=(max_Q_len,))\n",
        "\n",
        "# Embedding layer\n",
        "enc_emb = Embedding(Qs_VOCAB_SIZE, 128)(encoder_inputs)\n",
        "\n",
        "# Bidirectional lstm layer\n",
        "enc_lstm1 = Bidirectional(LSTM(128,return_sequences=True,return_state=True))\n",
        "encoder_outputs1, forw_state_h, forw_state_c, back_state_h, back_state_c = enc_lstm1(enc_emb)\n",
        "\n",
        "# Concatenate both h and c\n",
        "final_enc_h = Concatenate()([forw_state_h,back_state_h])\n",
        "final_enc_c = Concatenate()([forw_state_c,back_state_c])\n",
        "\n",
        "# get Context vector\n",
        "encoder_states =[final_enc_h, final_enc_c]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7vFHQ4rrT8E"
      },
      "outputs": [],
      "source": [
        "# decoder input\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "\n",
        "# decoder embedding with same number as encoder embedding\n",
        "dec_emb_layer = Embedding(As_VOCAB_SIZE, 128)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)   # apply this way because we need embedding layer for prediction\n",
        "\n",
        "# In encoder we used Bidirectional so it's having two LSTM's so we have to take double units(256*2=512) for single decoder lstm\n",
        "# LSTM using encoder's final states as initial state\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_states)\n",
        "\n",
        "# Using Attention Layer\n",
        "attention_layer = AttentionLayer()\n",
        "attention_result, attention_weights = attention_layer([encoder_outputs1, decoder_outputs])\n",
        "\n",
        "# Concat attention output and decoder LSTM output\n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_result])\n",
        "\n",
        "# Dense layer with softmax\n",
        "decoder_dense = Dense(As_VOCAB_SIZE, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDst-XBkrLT9"
      },
      "outputs": [],
      "source": [
        "base_learning_rate = 0.0009\n",
        "Opt = tf.keras.optimizers.RMSprop(learning_rate = base_learning_rate)\n",
        "checkpoint = ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    filepath=\"Final_Ws.h5\",\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
        "\n",
        "callbacks_list = [checkpoint, early_stopping]\n",
        "model.compile(optimizer=Opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSns2OVeVe-o"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-VWQZq5rAV9",
        "outputId": "ddf431ab-4bcd-4979-9694-9648567e113d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.5797 - accuracy: 0.9294\n",
            "Epoch 1: val_loss improved from inf to 0.46115, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1708s 3s/step - loss: 0.5797 - accuracy: 0.9294 - val_loss: 0.4612 - val_accuracy: 0.9335\n",
            "Epoch 2/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.4329 - accuracy: 0.9360\n",
            "Epoch 2: val_loss improved from 0.46115 to 0.43088, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1675s 3s/step - loss: 0.4329 - accuracy: 0.9360 - val_loss: 0.4309 - val_accuracy: 0.9359\n",
            "Epoch 3/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.9376\n",
            "Epoch 3: val_loss improved from 0.43088 to 0.41935, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1712s 3s/step - loss: 0.4122 - accuracy: 0.9376 - val_loss: 0.4194 - val_accuracy: 0.9368\n",
            "Epoch 4/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.4001 - accuracy: 0.9385\n",
            "Epoch 4: val_loss improved from 0.41935 to 0.41206, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1684s 3s/step - loss: 0.4001 - accuracy: 0.9385 - val_loss: 0.4121 - val_accuracy: 0.9373\n",
            "Epoch 5/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.3913 - accuracy: 0.9391\n",
            "Epoch 5: val_loss improved from 0.41206 to 0.40725, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1713s 3s/step - loss: 0.3913 - accuracy: 0.9391 - val_loss: 0.4072 - val_accuracy: 0.9377\n",
            "Epoch 6/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.3840 - accuracy: 0.9396\n",
            "Epoch 6: val_loss improved from 0.40725 to 0.40349, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1753s 3s/step - loss: 0.3840 - accuracy: 0.9396 - val_loss: 0.4035 - val_accuracy: 0.9380\n",
            "Epoch 7/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.3775 - accuracy: 0.9401\n",
            "Epoch 7: val_loss improved from 0.40349 to 0.40064, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1665s 3s/step - loss: 0.3775 - accuracy: 0.9401 - val_loss: 0.4006 - val_accuracy: 0.9382\n",
            "Epoch 8/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.3712 - accuracy: 0.9405\n",
            "Epoch 8: val_loss improved from 0.40064 to 0.39866, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1667s 3s/step - loss: 0.3712 - accuracy: 0.9405 - val_loss: 0.3987 - val_accuracy: 0.9385\n",
            "Epoch 9/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.3654 - accuracy: 0.9410\n",
            "Epoch 9: val_loss improved from 0.39866 to 0.39648, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1671s 3s/step - loss: 0.3654 - accuracy: 0.9410 - val_loss: 0.3965 - val_accuracy: 0.9387\n",
            "Epoch 10/10\n",
            "529/529 [==============================] - ETA: 0s - loss: 0.3597 - accuracy: 0.9414\n",
            "Epoch 10: val_loss improved from 0.39648 to 0.39502, saving model to Final_Ws.h5\n",
            "529/529 [==============================] - 1675s 3s/step - loss: 0.3597 - accuracy: 0.9414 - val_loss: 0.3950 - val_accuracy: 0.9387\n"
          ]
        }
      ],
      "source": [
        "# Training set\n",
        "encoder_input_data = X_train\n",
        "# Do the same to target data skip padding\n",
        "decoder_input_data = y_train[:,:-1]\n",
        "# Decoder target data has to be one step ahead\n",
        "decoder_target_data =  y_train[:,1:]\n",
        "\n",
        "# devlopment set\n",
        "encoder_input_test = X_val\n",
        "decoder_input_test = y_val[:,:-1]\n",
        "decoder_target_test=  y_val[:,1:]\n",
        "\n",
        "history = model.fit([encoder_input_data, decoder_input_data],decoder_target_data,\n",
        "                    epochs = 10,\n",
        "                    batch_size = 16,\n",
        "                    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
        "                    callbacks = callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "M6m_jhE8uxRv",
        "outputId": "d93fc084-418d-4496-e626-461c9c377e58"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'g', label='Validation loss')\n",
        "plt.title('Training And Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "HJVLxmTNCIN2",
        "outputId": "0f2840d2-204e-4cd5-b297-a953be591c29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff497e3dbb0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVfrA8e9L6IQaAgIBQ68hBCIdqSoKgqCoqEhZUbD9cNeCu666lrWxrrJrWQsqa0EXJUFFkSooWBDpRSlRQu8tlIS8vz/OzTAJSUggk0l5P88zz9w5t8x7rzhvzjn3niOqijHGGJNTJYIdgDHGmMLFEocxxphcscRhjDEmVyxxGGOMyRVLHMYYY3LFEocxxphcscRhzouIfCEiw/N622ASkUgRUREpGYBjq4g08pZfFZG/5mTbc/ieG0Xkq3ON05jsiD3HUfyIyBG/j+WBE8Ap7/Ntqvpe/kd1/kSkPrAR+I+qjj2P40QCm4FSqpqSYd2XwA+q+nCG8oHAf4CIjPtk2E6Bxqq6IQdx5Gjb7OINlLy61qZwshpHMaSqoWkv4HfgSr8yX9IIxF/cAXYzsB+4TkTKBOg73gFuEhHJUD4MeC+/frgLgPy41pkSkZD8/D5zJkscxkdEeohIoog8ICI7gLdEpKqIfCYiu0Vkv7cc4bfPfBG5xVseISLfiMgEb9vNInL5OW5bX0QWiMhhEZktIi+JyLvZxC64H7OHgGTgygzrVUTGiMivInLAO55460K8OPaIyCagXzaXKQ4IA7r5Hbsq0B+YLCLtRWSx9x3bReTfIlI6i5jfFpEn/D7f5+2zTURGZdi2n4j8LCKHRGSLiDzqt3qB935ARI6ISKe06+u3f2cR+VFEDnrvnf3WzReRx0XkW+96fyUi1bO6ADm41gNFZJkX60YR6euVVxORt7zz2y8icV55uli9Mv8mvbdF5BURmSEiR4GeZ7keiEhXEVnk/XfY4n3HRSKy0z/xiMhgEVme1bmazFniMBldAFQDLgRuxf0becv7XA84Bvw7m/07AOuB6sCzwJuZ/HWek23fB37A/Ug/ivuLPjtdgQhgCvARkFlfSn/gIqA1cC1wmVc+2lsXA8QC12T1Jap6zDv+zX7F1wLrVHU5rsnvHu+cOgG9gdvPEjvej+u9wCVAY6BPhk2Oet9ZBZfYxorIVd66i733Kl6tcXGGY1cDPgcm4q7n88DnIhLmt9kNwEigBlDaiyUrWV5rEWkPTAbu82K9GEjwVv8X1zTa0vuef2bzHRndADwJVAS+IZvrISIXAl8A/wLCgTbAMlX9EdgLXOp33GFevCY3VNVexfiF+5+6j7fcAzgJlM1m+zbAfr/P84FbvOURwAa/deUBBS7Izba4BJUClPdb/y7wbjZxvQHEecudcH8J1/Bbr0BXv88fAeO95bnAGL91l3rbl8ziu7oCB9KuE/AtcE8W244DpmWIo5G3/DbwhLc8CXjab7sm/ttmctwXgH96y5EZ4/Wu7zfe8jBcv4z//ouBEX7/XR7yW3c78OW5XGtcP88/M9mnFpAKVM1knS/WbK7T5LP8O/a/Hg/6X/MM2z2Aa1IE9wdSElArWP//FdaX1ThMRrtV9XjaBxEpLyL/EZHfROQQrlmkimTdzrwjbUFVk7zF0FxuWxvY51cGsCWrgEWkHDAEeM871mJc380NWX0f7gcjLa7aGY7/W1bf5R3/G2APcJWINATa42pIiEgTrzlvh3e9/o6rfZxNtjGISAcRmSeuyfAgMCaHx007dsZz+g2o4/c5q2uTTg6udV1cp3lGdXH/TffnMOaM0v33P8v1yCoGcH+AXCkiFXA1xYWquv0cYyq2LHGYjDLeZvcnoCnQQVUrcbpZJKvmp7ywHagmIuX9yupms/0goBLwsveDvQP3o5jTW3+3Zzh+vRzsMxnXVHITMFNVd3rlrwDrcHdDVQL+TM6u1dlieB+YDtRV1crAq37HPdutkdtwTY3+6gFbcxBXRme71luAhpnstwX337RKJuuO4mqcAIjIBZlsk/Ecs7seWcWAqm7F1bYG42pi/81sO5M9SxzmbCri+jUOeG3ljwT6C1X1N2AJ8KiIlBaRTmTogM1gOK6pJwrXlNYG6AJEi0hUDr7yI+BuEYnwOrrH52Cfybh+iNG4O63SVAQOAUdEpBmQ01tVPwJGiEgLL2FmvM4VcX+xH/f6EfxrU7txzUANsjj2DKCJiNwgIiVF5DqgBfBZDmPzd7Zr/SYwUkR6i0gJEakjIs28v+q/wCWcqiJSSkTS/ghZDrQUkTYiUhbXp3U22V2P94A+InKtd75hItLGb/1k4H7vHD45h2tQ7FniMGfzAlAO1zTzHfBlPn3vjbj2873AE8CHuOdN0hGROrgO6BdUdYff6ycv1pzUOl4HZuJ+wJaSgx8TVU0AFgEVcH/5prkX9yN22Dvuhzn4flT1C9y1ngts8N793Q48JiKHgYdxiSZt3yRcx/G33l1EHTMcey+u8/9PuOt5P9BfVffkJLY0ObnWqvoDrpP9n8BB4GtO13aG4fpD1gG7cP0/qOovwGPAbOBXXOf32WR3PX4HrvDOdx+wDIj223eaF9O0DM2hJofsAUBTKIjIh7g7lwJe4zFFn4hsxD3sOjvYsRRGVuMwBZJ3z31Dr7mjLzAQ9wyFMedFRK7G9ZlkrNWZHCpsTwab4uMCXJNRGJAIjFXVn4MbkinsRGQ+rn9nmKqmBjmcQsuaqowxxuSKNVUZY4zJlWLRVFW9enWNjIwMdhjGGFOo/PTTT3tUNTxjebFIHJGRkSxZsiTYYRhjTKEiIpmOomBNVcYYY3LFEocxxphcscRhjDEmV4pFH0dmkpOTSUxM5Pjx42ff2BQLZcuWJSIiglKlSgU7FGMKtGKbOBITE6lYsSKRkZFkPc+QKS5Ulb1795KYmEj9+vWDHY4xBVqxbao6fvw4YWFhljQMACJCWFiY1UCNyYFimzgASxomHfv3YEzOFNumKmOMKZJOnIA1a2DZMvj1V/j73/P8K4p1jSOY9u7dS5s2bWjTpg0XXHABderU8X0+efJktvsuWbKEu++++6zf0blz57wKF4Bx48ZRp04dUlNtbDhjCoRdu2DWLHjuObjpJoiKgtBQaNsWRo2CF1+Effvy/GutxhEkYWFhLFu2DIBHH32U0NBQ7r33Xt/6lJQUSpbM/D9PbGwssbGxZ/2ORYsW5U2wQGpqKtOmTaNu3bp8/fXX9OzZM8+O7S+78zam2EpJgV9+geXLXU1i+XL32uE3VXxEBERHw4AB0KaNW27YEEJC8jwcq3EUICNGjGDMmDF06NCB+++/nx9++IFOnToRExND586dWb9+PQDz58+nf//+gEs6o0aNokePHjRo0ICJEyf6jhcaGurbvkePHlxzzTU0a9aMG2+8kbRRkWfMmEGzZs1o164dd999t++4Gc2fP5+WLVsyduxYPvjgA1/5zp07GTRoENHR0URHR/uS1eTJk2ndujXR0dEMGzbMd35Tp07NNL5u3boxYMAAWrRoAcBVV11Fu3btaNmyJa+99ppvny+//JK2bdsSHR1N7969SU1NpXHjxuzevRtwCa5Ro0a+z8YUOgcOwIIF8K9/wR/+ALGxULEitGwJN9wA//wn7NwJl10Gzz8Pc+fCnj2wZQt89hk8+SQMGQJNmgQkaYDVOJxx41wWz0tt2sALL+R6t8TERBYtWkRISAiHDh1i4cKFlCxZktmzZ/PnP/+Zjz/++Ix91q1bx7x58zh8+DBNmzZl7NixZzyL8PPPP7N69Wpq165Nly5d+Pbbb4mNjeW2225jwYIF1K9fn6FDh2YZ1wcffMDQoUMZOHAgf/7zn0lOTqZUqVLcfffddO/enWnTpnHq1CmOHDnC6tWreeKJJ1i0aBHVq1dnXw6qykuXLmXVqlW+W2EnTZpEtWrVOHbsGBdddBFXX301qampjB492hfvvn37KFGiBDfddBPvvfce48aNY/bs2URHRxMefsa4bMYULKmpsHnz6dpDWm3iN7/hocLDXc3hjjvce5s20KwZBPlZI0scBcyQIUMI8f5KOHjwIMOHD+fXX39FREhOTs50n379+lGmTBnKlClDjRo12LlzJxEREem2ad++va+sTZs2JCQkEBoaSoMGDXw/1kOHDk33132akydPMmPGDJ5//nkqVqxIhw4dmDlzJv3792fu3LlMnjwZgJCQECpXrszkyZMZMmQI1atXB6BatWpnPe/27dune35i4sSJTJs2DYAtW7bw66+/snv3bi6++GLfdmnHHTVqFAMHDmTcuHFMmjSJkSNHnvX7jMlXSUmwcmX6JLFiBRw+7NaXKAFNm0KnTjBmjEsS0dFQqxYUwLv9LHHAOdUMAqVChQq+5b/+9a/07NmTadOmkZCQQI8ePTLdp0yZMr7lkJAQUlJSzmmbrMycOZMDBw4QFRUFQFJSEuXKlcuyWSsrJUuW9HWsp6amprsJwP+858+fz+zZs1m8eDHly5enR48e2T5fUbduXWrWrMncuXP54YcfeO+993IVlzF5avdu+PHH9H0Rv/wCaZPmVarkksLw4acTRMuWUL58cOPOBUscBdjBgwepU6cOAG+//XaeH79p06Zs2rSJhIQEIiMj+fDDDzPd7oMPPuCNN97wNWUdPXqU+vXrk5SURO/evXnllVcYN26cr6mqV69eDBo0iD/+8Y+EhYWxb98+qlWrRmRkJD/99BPXXnst06dPz7IGdfDgQapWrUr58uVZt24d3333HQAdO3bk9ttvZ/Pmzb6mqrRaxy233MJNN93EsGHDfDU2YwIuOdnVJBYvhu++c68NG06vr1/fJYahQ08nicjIAlmLyA1LHAXY/fffz/Dhw3niiSfo169fnh+/XLlyvPzyy/Tt25cKFSpw0UUXnbFNUlISX375Ja+++qqvrEKFCnTt2pVPP/2UF198kVtvvZU333yTkJAQXnnlFTp16sRf/vIXunfvTkhICDExMbz99tuMHj2agQMHEh0d7fvOzPTt25dXX32V5s2b07RpUzp27AhAeHg4r732GoMHDyY1NZUaNWowa9YsAAYMGMDIkSOtmcoE1o4dLjmkJYoff4Rjx9y6Cy5wTU2jR0PHjq4/olKl4MYbIMVizvHY2FjNOJHT2rVrad68eZAiKjiOHDlCaGgoqsodd9xB48aNueeee4IdVq4tWbKEe+65h4ULF57XcezfhfE5edI1N6UlicWLT3dclyrlnpXo2NEli44doV69Ql+TyEhEflLVM+79txpHMff666/zzjvvcPLkSWJiYrjtttuCHVKuPf3007zyyivWt2HOT2Ji+iSxdKl7Chugbl2XHP7v/9x7TAyULRvceIPIahzG+LF/F8XE8ePw00/pm522bnXrypaFdu1O1yQ6dgSvr7G4sRqHMaZ4UoWEhPRJYtky17ENrgP74otPJ4roaChdOqghF3SWOIwxRcvRo7BkSfo7nXbudOvKl4eLLoI//el0baJmzeDGWwhZ4jDGFF7JybB6tbu7Ke21ciWcOuXWN27shuZISxJRUWBjoZ03u4LGmMIhNdUNE+6fJH7+2fVXAFSp4sZ1evBBlyQ6dABv9AKTt2yQwyDp2bMnM2fOTFf2wgsvMHbs2Cz36dGjB2md/FdccQUHDhw4Y5tHH32UCRMmZPvdcXFxrFmzxvf54YcfZvbs2bkJP1s2/Lo5b6rw++/w8ccwfjz07g3VqrlxmoYNg9dfd8N0jBkD773nnszet88NMf7449CvnyWNALIaR5AMHTqUKVOmcNlll/nKpkyZwrPPPpuj/WfMmHHO3x0XF0f//v19I9E+9thj53ysjGz4dXNO9uxxNYgffnDvS5ac7pcoWRJat4brr3f9ExddBC1aWJNTEFmNI0iuueYaPv/8c994TQkJCWzbto1u3boxduxYYmNjadmyJY888kim+0dGRrJnzx4AnnzySZo0aULXrl19Q6+De0bjoosuIjo6mquvvpqkpCQWLVrE9OnTue+++2jTpg0bN25MN9z5nDlziImJISoqilGjRnHCu489MjKSRx55hLZt2xIVFcW6desyjcuGXzdndegQzJsHzz4L117r7moKD4crroC//Q02bXL9Ev/6l+vYPnzY3Tr76qtumPHWrS1pBJldfWDcl+NYtiNvh1Vvc0EbXuib9eCJ1apVo3379nzxxRcMHDiQKVOmcO211yIiPPnkk1SrVo1Tp07Ru3dvVqxYQevWrTM9zk8//cSUKVNYtmwZKSkptG3blnbt2gEwePBgRo8eDcBDDz3Em2++yV133cWAAQPo378/11xzTbpjHT9+nBEjRjBnzhyaNGnCzTff7BuHCqB69eosXbqUl19+mQkTJvDGG2+cEY8Nv27SOX7cDfLnX5tYv/70gH+Rka4Gcfvt7r1t2yI7TEdREtAah4j0FZH1IrJBRMZnsv5CEZkjIitEZL6IRGRYX0lEEkXk335l7URkpXfMiSKF9xn/tOYqcM1UaYMIfvTRR7Rt25aYmBhWr16drj8io4ULFzJo0CDKly9PpUqVGDBggG/dqlWr6NatG1FRUbz33nusXr0623jWr19P/fr1adKkCQDDhw9nwYIFvvWDBw8GoF27diQkJJyxf9rw61dddRWVKlXyDb8OMHfuXF//Tdrw63Pnzs2T4dejo6Pp2LGjb/j17777Lsvh19OGgLfh1wMgJcUNFf7mm67voV07NwFRx45w113w1VfQqBE8+ijMmOGmPd28GT76CO67D3r0sKRRSASsxiEiIcBLwCVAIvCjiExXVf9fwQnAZFV9R0R6AU8Bw/zWPw4sIL1XgNHA98AMoC/wxfnEml3NIJAGDhzIPffcw9KlS0lKSqJdu3Zs3ryZCRMm8OOPP1K1alVGjBiR7ZDi2RkxYgRxcXFER0fz9ttvM3/+/POKN21o9qyGZbfh14uZgwdh0SJYuBC++cb1S6QN+Fe5srvD6d57T/dLREQUubGciqtA1jjaAxtUdZOqngSmAAMzbNMCmOstz/NfLyLtgJrAV35ltYBKqvqdurFSJgNXBe4UAis0NJSePXsyatQoX23j0KFDVKhQgcqVK7Nz506++CL7nHjxxRcTFxfHsWPHOHz4MJ9++qlv3eHDh6lVqxbJycnpfiQrVqzI4bQJZPw0bdqUhIQENnjDQv/3v/+le/fuOT6ftOHXExISSEhIYPPmzcyaNSvd8OsAp06d4uDBg/Tq1Yv//e9/7N27F8DXVJU2/DpwzsOvL1iwgM2bN6c7Lpweft1/wiyTQ9u3u9rBXXe5sZqqVnX9Es8958Z0uvVWePdd1xS1bx/Mng1PPQWDB7uxnixpFBmBTBx1gC1+nxO9Mn/LgcHe8iCgooiEiUgJ4B/AvZkcM/EsxyxUhg4dyvLly32JIzo6mpiYGJo1a8YNN9xAly5dst2/bdu2XHfddURHR3P55ZenGxr98ccfp0OHDnTp0oVmzZr5yq+//nqee+45YmJi2Lhxo6+8bNmyvPXWWwwZMoSoqChKlCjBmDFjcnQeacOv+w//nnH49Xnz5hEVFUW7du1Ys2YNLVu29A2/Hh0dzR//+EcARo8ezddff010dDSLFy/Odvj1lJQUmjdvzvjx4zMdfj06OprrrrvOt8+AAQM4cuSINVOdjap7ZmLSJBg50jUx1a4N113nysLC4JFHYM4cN0f299+7CdFuvNHNdV3C7rspygI2yKGIXAP0VdVbvM/DgA6qeqffNrWBfwP1cU1SVwOtgJuA8qr6rIiMAGJV9U4RiQWeVtU+3v7dgAdU9Yy2EBG5FbgVoF69eu1+85/HFxvMrrg62/DrxfbfxalTrn9i4cLTTU87drh1YWHQtSt06+ZeMTFBn/Pa5I9gDHK4Fajr9znCK/NR1W14NQ4RCQWuVtUDItIJ6CYitwOhQGkROQK86B0ny2P6Hfs14DVwo+PmyRmZQs2GX/dz/Li7yyktSSxa5G6TBTevRO/epxNFs2ZWgzDpBDJx/Ag0FpH6uB/364Eb/DcQkerAPlVNBR4EJgGo6o1+24zA1TjGe58PiUhHXOf4zcC/AngOpggZP34848efcXNf8XDgwOmO7IUL3W2xaTcdtGwJN9zgkkTXri5xGJONgCUOVU0RkTuBmUAIMElVV4vIY8ASVZ0O9ACeEhHFNVXdkYND3w68DZTD3U11zndUqSqF+G5ek8eK1Nw027efThILF7pmKFX34Fy7dnD33S5RdOnimqKMyYViO5HT5s2bqVixImFhYZY8DKrK3r17OXz4cLrnRAqFtI5s/0SxaZNbV6GCm2cirY+iQwdXZkwO2EROGURERJCYmGhDThifsmXLEhERcfYNg00V1q6F+fPda8GC0+M6Va/uksQdd7hE0aaNdWSbPFdsE0epUqUK31+WpnhShXXr3PhOacki7Q+eunXhkkvSd2RbDdoEWLFNHMYUWGmJIi1JzJ/vhucA9/R1375ueI4ePdwAgZYoTD6zxGFMsKm6p639axRpiaJOHbj0Upckeva0RGEKBEscxuS3tEThX6NI66PwTxQ9ekCDBpYoTIFjicOYQFN1M9T5J4q0p7Jr14Y+fU4nioYNLVGYAs8ShzF57WyJolcv1+xkicIUUpY4jDlfac9R+CeK7dvdulq1XKJIq1E0amSJwhR6ljiMORe//eYmJkrr0PZPFGlJomdPSxSmSLLEYUxOqMKyZRAf717LvKmGL7jgdLNTjx7QuLElClPkWeIwJivJyfD11y5RTJ8Ov//ukkLnzvDss9C/vz1wZ4olSxzG+Dt0CL74wiWLGTPc9Kjlyrmnsx95xCWLGjWCHaUxQWWJw5itW12NIj4e5s51NY3q1d2UpwMHuqRRvnywozSmwLDEYYofVVi16nR/RdrIyY0aueHGr7rKjShrc5IbkylLHKZ4SEmBb789nSzShh3v0AH+/ndXs2je3PorTKGUqqmcPHUy01fjao3zfOoISxym6Dp6FGbOdInis89g3z4oXdo9qf3AA3Dlle72WWPywPGU42w9tJXEQ4nsOLKD4ynHs/wxz/g6cepEjrfN7HVKT2Ud11+OU6ZkmTw9V0scpmjZuRM+/RTi4mD2bDhxAqpWhX79XK3issugYsVgR2kKmaTkJBIPJWb52nJoC3uS9uToWCESQumQ0jl6hZYOzfG2Wb1CSuR9k6slDlP4rVt3ugnqu+9cH0ZkJIwZ45JF1642mZHJ0uEThzNPCIe9pHBwC/uP7z9jv7ByYURUiqBu5bp0qNOBiEoRvletirUoV7Kc78e7TMkylA4pTakSpQLyQ57fLHGYwufUKZcg0pLFL7+48nbt4G9/c8kiKsr6K4o5VeXgiYNnrSkcOnHojH1rVKhBRKUIIqtE0q1et3RJIaJSBHUq1qFcqXJBOKuCwRKHKTw2bYJXXoHJk918FSVLuqe2774bBgxws+GZYkNV2Z20m037N7Fp/yY27tvI5gOb2XJoiy8xHDl5JN0+gnBB6AVEVIqgSVgTetXvRd1KddMlhdoVa+d5n0BRY4nDFGypqW5MqH//2z2QV6KEq1EMGQKXXw6VKwc7QhNAJ1JOkHAgwZccNu3fxMb9G33LR5OPptu+VmgtLqxyIa1qtKJvw76+piRfE1JoLUqFWLPl+bLEYQqmAwfgrbfg5ZdhwwaoWRMeeghuu81NdmSKhIy1hozJYeuhrSjq275cyXI0qNqABlUb0Lt+b99yg6oNiKwSWaybj/KTJQ5TsKxYAS+9BO++C0lJblyoxx6Dq692t9KaQudEygl+O/gbG/edrilsOnA6SWRsTqpdsTYNqjagV/1eNKjSgIbVGvqSQ80KNfP8mQSTe5Y4TPAlJ8O0aa45auFCKFsWbrwR7rgDYmKCHZ05i+RTyexJ2sPvB39P14yU9ko8lJhlraFnZE/fcsOqDa3WUEhY4jDBs307vP46vPqqW65fH557DkaNgmrVgh1dsXXy1El2H93N7qTd6d53Hd3lljOUZ3araq3QWi4x1O9JgyoN0jUpXRB6gdUaCrmAJg4R6Qu8CIQAb6jq0xnWXwhMAsKBfcBNqprolU8DSgClgH+p6qvePkOBPwMKbPP2ydmTNyb4VN3QHy+9BFOnuqFA+vZ1CaRvXxsfKgCOpxw/IxHsOrrrdFmG8sxuTwUoISUILx9OeIVwwsuH0+aCNu6zV1avcj1fX0P5UjYoZFEmqnr2rc7lwCIhwC/AJUAi8CMwVFXX+G3zP+AzVX1HRHoBI1V1mIiU9mI7ISKhwCqgM7ALlyxaqOoeEXkWSFLVR7OLJTY2VpekDWRngiMpCd5/3zVHLV/u7oYaNQrGjnWTH5lc25u0l5W7VvLbgd/S1wIy1BAy9iGkKVmiZLpEkPZeo0KNTMurlqtKCSmRz2dpgklEflLV2IzlgaxxtAc2qOomL4ApwEBgjd82LYA/esvzgDgAVT3pt00ZXM0DQLxXBRHZC1QCNgTqBEwe2LjR3Rk1aZK7UyoqCv7zH9eHUaFCsKMrFI6cPMKa3WtYtWsVK3euZNXuVazatYodR3ak2650SOl0P/QNqzWkRvkaZySAtPcqZatYk5E5J4FMHHWALX6fE4EOGbZZDgzGNWcNAiqKSJiq7hWRusDnQCPgPlXdBiAiY4GVwFHgV+COzL5cRG4FbgWoV69eXp2TyYnUVDe44L//7SZFCglxc1vceacb/sN+rDJ18tRJftn7i0sOu1b5EsSm/Zt825QrWY6WNVrSt1FfWoW3IqpmFA2qNqBGhRpULF3REoHJF8HuHL8X+LeIjAAWAFuBUwCqugVoLSK1gTgRmYrrBxkLxACbgH8BDwJPZDywqr4GvAauqSrgZ2Jg//7Tz15s3Ojm4374Ybj1VqhdO9jRFRipmkrCgYR0CWLlzpWs37uelNQUwA2E17R6U2JrxzKyzUha1WhFqxqtqF+lfpEY68gUboFMHFsB/zEgIrwyH68WMRjA68u4WlUPZNxGRFYB3YDfvLKN3j4fAeMDdQImh5Yvd7WL996DY8dcreKJJ1wtoxg/e6Gq7DiywyWHXatYucslitW7V5OUnOTbLrJKJK1qtGJA0wG+BNE0rKkNe2EKrEAmjh+BxiJSH5cwrqE/WvIAAB5/SURBVAdu8N9ARKoD+1Q1FVdzmOSVRwB7VfWYiFQFugL/BPYCLUQkXFV34zre1wbwHExWTp48/ezFN9+4ebnTnr1o0ybY0eW7A8cPsHrX6nQJYtWuVew9tte3TY0KNYiqEcXotqN9CaJleEsqlrFh3k3hErDEoaopInInMBN3O+4kVV0tIo8BS1R1OtADeEpEFNdUldZf0Rz4h1cuwARVXQkgIn8DFohIMq4GMiJQ52AysW0bvPaa6+DesQMaNIB//ANGjnTzXhRxB48fZN2edazds/Z0h/WulSQeSvRtU7F0RVrVaMXg5oNpVaMVUTWiaFmjJTUq1Ahi5MbknYDdjluQ2O24eWDHDrjnntPPXlx+uevs7tvXDTxYhKgq2w5vY+2etS5J7F7rW95+ZLtvu9IhpWlevbkvOaTVIupVrmed1KZICMbtuKaoWLQIrrnG3U57993u2YtGjYId1XlLPpXMxv0bz0gO6/as4/DJw77tKpWpRPPqzbms0WU0C2tG8/DmNKvejAZVG1CyhP0vZIof+1dvsqbq7pAaNw4uvNDdYhsVFeyocu3wicOs37uetbvX+pqZ1u5Zy4Z9G3x3MQHUqViH5uHNGR493JccmldvbkNkGJOBJQ6TuWPH3NSrkye7+brffReqVAl2VFlSVXYe3XlGcli3Z126/oeSJUrSqFojmlVvxqBmg2he3SWIZtWbWSe1MTlkicOcafNmdyvt8uVuKtaHHiow/Riqysb9G31NS/7NSweOn76TO7R0KM2rN6dnZE9fcmge3pyGVRvaRD7GnCdLHCa9mTNh6FDXTPXZZ3DFFcGOiMRDiczeNNv32nl0p29drdBaNKvejBta3ZCueal2xdrWvGRMgFjiME5qKvz97+5J76go+OQTaNgwKKEcPH6QeQnzfIli/d71gHsOok+DPvSM7ElUjSiaVm9KlbIFt/nMmKLKEoeBgwfh5pth+nS44QY3xHn5/BsW+0TKCb5L/M4lis2z+WHrD6RqKhVKVaB7ZHdua3cbfRr0oVWNVlaLMKYAsMRR3K1eDYMGuX6NF1+Eu+4K+CCEqZrKyp0rfYliwW8LSEpOIkRCaF+nPQ91e4g+DfrQIaIDpUOK75AlxhRUljiKs48+cnNihIbC3LnQrVvAvur3g7/7mp7mbJ7DrqO7AGhevTl/iPkDfRr0ofuF3alctnLAYjDG5A1LHMVRSgo8+CBMmACdOrmnwfN49Nr9x/an66f4dd+vgOvMvqzhZfRp0Ife9XtTp1KdPP1eY0zgWeIobnbtguuvh3nz3ICEzz+fJyPYnkg5waIti3zNT0u2LSFVUwktHUqPyB7ccdEd9GnQhxbhLayfwphCzhJHcfLDD3D11bBnD7zzjusQP0epmsqKnSuYtXEWszfPZuFvCzmWcoySJUrSMaIjD1/8MH0a9KF9nfb23IQxRYwljuLi9dfdoIS1a7uxp2Jicn2I3w78xqxNs3z9FHuS9gDQMrwlt7a71ddPYU9gG1O0WeIo6o4fdwnjzTfhssvcZEthYbk6xDe/f8Mz3z7DZ798BkDtirXp17ifr5+iVsVagYjcGFNAWeIoyn7/3TVNLVkCf/mLGz4kJGfTjqZqKjN+ncHT3zzNt1u+JaxcGI92f5RrW15Ls+rNrJ/CmGLMEkdRNWeO6wQ/cQLi4mDgwBztlnwqmQ9Xf8gz3z7Dql2rqFe5HhP7TmRUzCgqlK4Q4KCNMYWBJY6iRtXdZjt+PDRr5oYOadr0rLslJSfx5tI3mbB4Ar8f/J2W4S3576D/cl3L66xz2xiTjiWOouTwYfdA39SpMGQITJrkHu7Lxr5j+3jph5eY+MNE9iTtoUvdLrx0xUtc0fgKSkjBGBHXGFOwWOIoKtavd0OHrF/vahx//GO2Q4ckHkrkn4v/yX9++g9Hk4/Sv0l/HujyAF3rdc3HoI0xhZEljqJg2jQYPhzKlIFZs6BXryw3XbdnHc9++yzvrniXVE1laNRQ7u98P1E1C9/MfsaY4LDEUZidOgV//Ss89RRcdBF8/DHUrZvppt8nfs8z3z5D3Lo4ypYsy23tbuNPnf9EZJXI/I3ZGFPoWeIorPbudRMuzZoFo0fDxIlQtmy6TVSVrzZ+xdPfPs38hPlULVuVhy5+iLva30V4hfAgBW6MKewscRRGS5e6qV23b3dPhN9yS7rVKakpfLzmY57+9mmW7VhGnYp1+Mel/2B029H2VLcx5rxZ4ihs3nkHxoyB8HD45hvXROU5nnKct5e9zYRFE9i4fyNNw5oyacAkbmx9o81rYYzJMwG931JE+orIehHZICLjM1l/oYjMEZEVIjJfRCL8ypeKyDIRWS0iY/z2KS0ir4nILyKyTkSuDuQ5FBgnT8Ltt8OIEdC5M/z0ky9pHDx+kKe/eZrIFyIZ+/lYwsqH8cm1n7DmjjWMjBlpScMYk6cCVuMQkRDgJeASIBH4UUSmq+oav80mAJNV9R0R6QU8BQwDtgOdVPWEiIQCq7x9twF/AXapahMRKQFUC9Q5FBhbt7rnMhYvhvvuc3ODlyzJ9sPbefH7F3llySscOnGIyxpexgNdHqBHZA8bEsQYEzCBbKpqD2xQ1U0AIjIFGAj4J44WwB+95XlAHICqnvTbpgzpa0ajgGbedqnAnkAEX2CcOOEmW9q3z83YN2QIG/Zt4Llvn+Pt5W+TkprCkBZDeKDLA8TUyv2It8YYk1uBTBx1gC1+nxOBDhm2WQ4MBl4EBgEVRSRMVfeKSF3gc6ARcJ+qbhORKt5+j4tID2AjcKeq7sz45SJyK3ArQL169fLurPLbvHmwZQtMm8bSDvV4Zup1TF0zlVIlSjGyzUju7Xwvjao1CnaUxphiJNhjStwLdBeRn4HuwFbgFICqblHV1rjEMVxEauISXQSwSFXbAotxzV1nUNXXVDVWVWPDwwvxrafx8SxsUpbLDr5Eu9fa8eWGL7m/8/0kjEvg1f6vWtIwxuS7HNU4RKQCcExVU0WkCa6p6AtVTc5mt62A/9NoEV6Zj9dnMdj7jlDgalU9kHEbEVkFdAM+BpKAT7zV/wP+kJNzKJRSU/ns5w8ZOPQ44btX8nTvpxkTO4bKZSsHOzJjTDGW0xrHAqCsiNQBvsJ1YL99ln1+BBqLSH0RKQ1cD0z330BEqnsd3AAPApO88ggRKectVwW6AutVVYFPgR7ePr1J32dSpCyb+z7X995PTJlINty9gQe6PmBJwxgTdDlNHKKqSbjawcuqOgRomd0OqpoC3AnMBNYCH6nqahF5TEQGeJv1ANaLyC9ATeBJr7w58L2ILAe+Biao6kpv3QPAoyKyApfA/pTDcyhUth7aSv9vbqfqMZh+42eEls5+lFtjjMkvOe0cFxHpBNzI6aahs04lp6ozgBkZyh72W54KTM1kv1lA6yyO+RtwcQ7jLpSOnDzClR9cycGUo3zz60XUrpdtjjbGmHyV0xrHOFxT0jSv1tAAd/usyWOnUk9x4yc3snzncj78KJXoPjcGOyRjjEknRzUOVf0a12SE1yexR1XvDmRgxdX9s+5n+vrp/Kv0VVzxa86nfDXGmPySoxqHiLwvIpW8u6tWAWtE5L7Ahlb8vLrkVZ7/7nnuan8Xd87YA9HREBkZ7LCMMSadnDZVtVDVQ8BVwBdAfVzHtMkjMzfM5M4Zd9KvcT/+2fbPsGiR1TaMMQVSThNHKREphUsc073nNzRwYRUvq3atYsj/htCqRis+uPoDQmZ8AampljiMMQVSThPHf4AEoAKwQEQuBA4FKqjiZMeRHfR7vx+hpUP57IbP3HwZ8fFuJr8YG3vKGFPw5ChxqOpEVa2jqleo8xvQM8CxFXlJyUkM+GAAe5L28OnQT4moFAFJSfDVV662YSPcGmMKoJx2jlcWkedFZIn3+geu9mHOUaqmcvO0m1mybQnvD36fdrXbuRWzZsGxY9ZMZYwpsHLaVDUJOAxc670OAW8FKqji4M9z/szHaz9mwqUTGNjML0nEx0PlytC9e/CCM8aYbOT0yfGGquo/097fRGRZIAIqDt5Y+gbPfPsMY9qN4Z6O95xeceoUfPop9OsHpUoFL0BjjMlGTmscx0Ska9oHEekCHAtMSEXbnE1zGPv5WC5teCkTL5+Yfqa+RYtgzx5rpjLGFGg5rXGMASaLSNrQrPuB4YEJqehau3stV390NU3DmvLRNR9RKiRDrSI+HkqXhr59gxOgMcbkQE6HHFkORItIJe/zIREZB6wIZHBFye6ju+n3fj/KlCzD5zd8fubw6KoQFwe9ekGlSsEJ0hhjciBXMwCq6iHvCXI4PVe4OYvjKce56sOr2H5kO9Ovn86FVS48c6M1a2DjRmumMsYUeOcz57g9ZJADqZrKyPiRLNqyiP8N+R8dIjJOu+6Jj3fvAwZkvt4YYwqI85lz3IYcyYFH5z/KlFVTeKr3U1zT4pqsN4yLg/btoXbt/AvOGGPOQbY1DhE5TOYJQoByAYmoCJm8fDKPL3icP8T8gQe6PJD1htu2wY8/wpNPZr2NMcYUENkmDlWtmF+BFDVfJ3zNLdNvoVf9Xrzc7+X0t91mNN2bit36N4wxhcD5NFWZLPyy9xcGfTiIhtUaMnXIVEqHlM5+h7g4aNQIWrTInwCNMeY8WOLIY3uT9tLv/X6ElAjh8xs+p2q5qtnvcOgQzJ1rgxoaYwqN87mrymRwIuUEgz4cxJaDW5g7fC4NqjY4+05ffgnJydZMZYwpNCxx5BFVZfSno1n4+0LeH/w+net2ztmO8fFQvTp0zuH2xhgTZNZUlUeeWPAE/13xXx7r8RhDo4bmbKfkZPj8c7jySggJCWyAxhiTRyxx5IEPVn7Aw/MfZljrYTx08UM53/Hrr+HgQWumMsYUKgFNHCLSV0TWi8gGERmfyfoLRWSOiKwQkfkiEuFXvlRElonIahEZk8m+00VkVSDjz4lFWxYxMn4kF194Ma9f+Xr2t91mFB8P5crBJZcELkBjjMljAUscIhICvARcDrQAhopIxvtNJwCTVbU18BjwlFe+Heikqm2ADsB4EfE9Ui0ig4EjgYo9pzbu28jAKQOpW7kun1z7CWVKlsn5zqoucVx6KZQvH7ggjTEmjwWyxtEe2KCqm1T1JDAFyNgm0wKY6y3PS1uvqidV9YRXXsY/ThEJxQ2w+EQAYz+r/cf20/+D/qRqKp/f8Dlh5cNyd4Cff4YtW6yZyhhT6AQycdQBtvh9TvTK/C0HBnvLg4CKIhIGICJ1RWSFd4xnVHWbt93jwD+ApOy+XERuTZsjfffu3ed3JhmcPHWSa/53DRv3bWTaddNoEtYk9weJj4cSJaB//zyNzRhjAi3YneP3At1F5GegO7AVOAWgqlu8JqxGwHARqSkibXDT2E4724FV9TVVjVXV2PDw8DwLWFUZ+9lY5m6eyxsD3uDiCy8+twPFxUGXLpCHsRljTH4I5HMcW4G6fp8jvDIfrxYxGHxNUFer6oGM23id4N2AcCBWRBJwsdcQkfmq2iNQJ5HRs98+y6Rlk3io20PcHH3zuR1k82ZYsQImTMjb4IwxJh8EssbxI9BYROqLSGngemC6/wYiUl1E0mJ4EJjklUeISDlvuSrQFVivqq+oam1VjfTKfsnPpDF1zVTGzxnP9a2u57Gej537gWxQQ2NMIRawxKGqKcCdwExgLfCRqq4WkcdEJG22oh7AehH5BagJpI0r3hz4XkSWA18DE1R1ZaBizYnvE79n2LRhdIroxFsD38rdbbcZxcVBy5ZuYENjjClkRLXoz8cUGxurS5YsOef9Ew4k0OGNDlQoVYHvb/me8Arn0S+xbx/UqAEPPGDzbxhjCjQR+UlVYzOW21hVZ3Hw+EH6v9+fEyknmD98/vklDXBDjJw6Zc1UxphCyxJHNlJSU7h26rWs37ueL2/8kubhzc//oHFxbnrY2DOSuDHGFArBvh23wFJV7ppxF19t/IpX+71K7wa9z/+gx4/DzJkwYIB7hsMYYwoh+/XKQnJqMtuPbOeBLg/wh7Z/yJuDzpkDR49aM5UxplCzpqoslA4pzcfXfnx+d09lFB8PFStCz555d0xjjMlnljiyEVIiD+fISE11z29cfjmUycVgiMYYU8BYU1V++f572LnTmqmMMYWeJY78Eh8PJUvCFVcEOxJjjDkvljjyS1wc9OgBVaoEOxJjjDkvljjyw/r17mXNVMaYIsASR36Ij3fvAwZkv50xxhQCljjyQ1wctG0L9eoFOxJjjDlvljgCbedO+O47a6YyxhQZljgC7dNPQdUShzGmyLDEEWhxcRAZCa1bBzsSY4zJE5Y4AunIEZg929U28nLoEmOMCSJLHIH01Vdw4oQ1UxljihRLHIEUHw9Vq0K3bsGOxBhj8owljkBJSYHPPoP+/d1QI8YYU0RY4giUb75x84tbM5UxpoixxBEo8fFu+PTLLgt2JMYYk6cscQSCqrsNt08fCA0NdjTGGJOnLHEEwsqVkJBgzVTGmCLJEkcgxMe75zauvDLYkRhjTJ4LaOIQkb4isl5ENojI+EzWXygic0RkhYjMF5EIv/KlIrJMRFaLyBivvLyIfC4i67zypwMZ/zmLi4OOHeGCC4IdiTHG5LmAJQ4RCQFeAi4HWgBDRaRFhs0mAJNVtTXwGPCUV74d6KSqbYAOwHgRqZ22j6o2A2KALiJyeaDO4Zxs2QJLl1ozlTGmyApkjaM9sEFVN6nqSWAKkPHXtAUw11uel7ZeVU+q6gmvvExanKqapKrz0rYBlgIRATyH3Js+3b1b4jDGFFGBTBx1gC1+nxO9Mn/LgcHe8iCgooiEAYhIXRFZ4R3jGVXd5r+jiFQBrgTmZPblInKriCwRkSW7d+8+75PJsbg4aNoUmjXLv+80xph8FOzO8XuB7iLyM9Ad2AqcAlDVLV4TViNguIjUTNtJREoCHwATVXVTZgdW1ddUNVZVY8PDwwN9Hs6BAzB/vtU2jDFFWiATx1agrt/nCK/MR1W3qepgVY0B/uKVHci4DbAK8B/w6TXgV1V9IRCBn7MvvnBDjVjiMMYUYYFMHD8CjUWkvoiUBq4HpvtvICLVRSQthgeBSV55hIiU85arAl2B9d7nJ4DKwLgAxn5u4uKgZk3o0CHYkRhjTMAELHGoagpwJzATWAt8pKqrReQxERngbdYDWC8ivwA1gSe98ubA9yKyHPgadyfVSu923b/gOtXTbte9JVDnkCsnTrgax5VXQkhIsKMxxpiACeiwrao6A5iRoexhv+WpwNRM9psFnDFlnqomAgVzRqT58+HwYWumMsYUecHuHC864uOhQgXo3TvYkRhjTEBZ4sgLqakucVx2GZQrF+xojDEmoCxx5IWffoJt26yZyhhTLFjiyAvx8a5DvF+/YEdijDEBZ4kjL8TFuXnFw8KCHYkxxgScJY7ztXEjrF5tzVTGmGLDEsf5io9375Y4jDHFhCWO8xUXB61bQ/36wY7EGGPyhSWO87FnD3z7rdU2jDHFiiWO8/HZZ+4ZDkscxphixBLH+YiLg4gIaNs22JEYY0y+scRxrpKS4KuvXG1DCubwWcYYEwiWOM7V7Nlw7Jg1Uxljih1LHOcqLg4qV4bu3YMdiTHG5CtLHOfi1CnXMX7FFVC6dLCjMcaYfGWJ41wsXgy7d1szlTGmWLLEcS7i46FUKbj88mBHYowx+c4SR26puv6NXr2gUqVgR2OMMfnOEkdurV0LGzZYM5UxptiyxJFbaYMaDhgQ3DiMMSZILHHkVlwcXHQR1KkT7EiMMSYoLHHkxrZt8MMP1kxljCnWLHHkxqefundLHMaYYswSR27ExUHDhtCyZbAjMcaYoAlo4hCRviKyXkQ2iMj4TNZfKCJzRGSFiMwXkQi/8qUiskxEVovIGL992onISu+YE0XyaYTBw4dh7lwb1NAYU+wFLHGISAjwEnA50AIYKiItMmw2AZisqq2Bx4CnvPLtQCdVbQN0AMaLSG1v3SvAaKCx9+obqHNI58sv4eRJa6YyxhR7gaxxtAc2qOomVT0JTAEy/uq2AOZ6y/PS1qvqSVU94ZWXSYtTRGoBlVT1O1VVYDJwVQDP4bS4OKheHTp3zpevM8aYgiqQiaMOsMXvc6JX5m85MNhbHgRUFJEwABGpKyIrvGM8o6rbvP0Tz3LMvJecDDNmQP/+ULJkwL/OGGMKsmB3jt8LdBeRn4HuwFbgFICqbvGasBoBw0WkZm4OLCK3isgSEVmye/fu84tywQI4cMCaqYwxhsAmjq1AXb/PEV6Zj6puU9XBqhoD/MUrO5BxG2AV0M3bPyK7Y/rt95qqxqpqbHh4+PmdSXw8lC0Ll1xyfscxxpgiIJCJ40egsYjUF5HSwPXAdP8NRKS6iKTF8CAwySuPEJFy3nJVoCuwXlW3A4dEpKN3N9XNQHwAz+H0oIaXXgoVKgT0q4wxpjAIWOJQ1RTgTmAmsBb4SFVXi8hjIpI20FMPYL2I/ALUBJ70ypsD34vIcuBrYIKqrvTW3Q68AWwANgJfBOocAFi2DLZssWYqY4zxBLSnV1VnADMylD3stzwVmJrJfrOA1lkccwnQKm8jzUZ8vHtuo3//fPtKY4wpyILdOV7wxcVBly5Qo0awIzHGmALBEkd2EhJg+XJrpjLGGD+WOLIz3evLt8RhjDE+ljiyExcHLVpA48bBjsQYYwoMeww6K6rQpg3UrXv2bY0xphixxJEVEXj++WBHYYwxBY41VRljjMkVSxzGGGNyxRKHMcaYXLHEYYwxJlcscRhjjMkVSxzGGGNyxRKHMcaYXLHEYYwxJldEVYMdQ8CJyG7gt2DHcZ6qA3uCHUQBYdciPbse6dn1OO18r8WFqnrGFKrFInEUBSKyRFVjgx1HQWDXIj27HunZ9TgtUNfCmqqMMcbkiiUOY4wxuWKJo/B4LdgBFCB2LdKz65GeXY/TAnItrI/DGGNMrliNwxhjTK5Y4jDGGJMrljgKMBGpKyLzRGSNiKwWkf8LdkwFgYiEiMjPIvJZsGMJNhGpIiJTRWSdiKwVkU7BjilYROQe7/+TVSLygYiUDXZM+UlEJonILhFZ5VdWTURmiciv3nvVvPguSxwFWwrwJ1VtAXQE7hCRFkGOqSD4P2BtsIMoIF4EvlTVZkA0xfS6iEgd4G4gVlVbASHA9cGNKt+9DfTNUDYemKOqjYE53ufzZomjAFPV7aq61Fs+jPtRqBPcqIJLRCKAfsAbwY4l2ESkMnAx8CaAqp5U1QPBjSqoSgLlRKQkUB7YFuR48pWqLgD2ZSgeCLzjLb8DXJUX32WJo5AQkUggBvg+uJEE3QvA/UBqsAMpAOoDu4G3vKa7N0SkQrCDCgZV3QpMAH4HtgMHVfWr4EZVINRU1e3e8g6gZl4c1BJHISAiocDHwDhVPRTseIJFRPoDu1T1p2DHUkCUBNoCr6hqDHCUPGqKKGy8tvuBuGRaG6ggIjcFN6qCRd2zF3ny/IUljgJORErhksZ7qvpJsOMJsi7AABFJAKYAvUTk3eCGFFSJQKKqptVCp+ISSXHUB9isqrtVNRn4BOgc5JgKgp0iUgvAe9+VFwe1xFGAiYjg2q/XqurzwY4n2FT1QVWNUNVIXMfnXFUttn9VquoOYIuINPWKegNrghhSMP0OdBSR8t7/N70ppjcKZDAdGO4tDwfi8+KgljgKti7AMNxf1su81xXBDsoUKHcB74nICqAN8PcgxxMUXq1rKrAUWIn7bStWQ4+IyAfAYqCpiCSKyB+Ap4FLRORXXK3s6Tz5LhtyxBhjTG5YjcMYY0yuWOIwxhiTK5Y4jDHG5IolDmOMMbliicMYY0yuWOIw5hyJyCm/26SXiUiePbUtIpH+o5waU5CUDHYAxhRix1S1TbCDMCa/WY3DmDwmIgki8qyIrBSRH0SkkVceKSJzRWSFiMwRkXpeeU0RmSYiy71X2lAZISLyujfHxFciUs7b/m5vjpYVIjIlSKdpijFLHMacu3IZmqqu81t3UFWjgH/jRvQF+Bfwjqq2Bt4DJnrlE4GvVTUaN9bUaq+8MfCSqrYEDgBXe+XjgRjvOGMCdXLGZMWeHDfmHInIEVUNzaQ8Aeilqpu8QSp3qGqYiOwBaqlqsle+XVWri8huIEJVT/gdIxKY5U3Ag4g8AJRS1SdE5EvgCBAHxKnqkQCfqjHpWI3DmMDQLJZz44Tf8ilO90n2A17C1U5+9CYuMibfWOIwJjCu83tf7C0v4vR0pjcCC73lOcBY8M2nXjmrg4pICaCuqs4DHgAqA2fUeowJJPtLxZhzV05Elvl9/lJV027JreqNWHsCGOqV3YWbre8+3Mx9I73y/wNe80YzPYVLItvJXAjwrpdcBJhYzKeLNUFgfRzG5DGvjyNWVfcEOxZjAsGaqowxxuSK1TiMMcbkitU4jDHG5IolDmOMMbliicMYY0yuWOIwxhiTK5Y4jDHG5Mr/A8vEc9W8ngreAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc , 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'g', label='Validation Accuracy')\n",
        "plt.title('Training And Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmDS76OjVi_O"
      },
      "source": [
        "##Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSZhOGz4QZ3X"
      },
      "outputs": [],
      "source": [
        "# Its good to restart runtime and create model and load weights\n",
        "model.load_weights(\"Final_Ws.h5\")\n",
        "\n",
        "############################### INFERENCE MODEL ################################\n",
        "# encoder Inference model\n",
        "encoder_model = Model(encoder_inputs, outputs = [encoder_outputs1, final_enc_h, final_enc_c])\n",
        "\n",
        "# Decoder Inference\n",
        "decoder_state_h = Input(shape=(256,)) # This numbers has to be same as units of lstm's on which model is trained\n",
        "decoder_state_c = Input(shape=(256,))\n",
        "\n",
        "# we need hidden state for attention layer\n",
        "# 28 is maximum length of a question sentence\n",
        "decoder_hidden_state_input = Input(shape=(28,256))\n",
        "# get decoder states\n",
        "dec_states = [decoder_state_h, decoder_state_c]\n",
        "\n",
        "# embedding layer\n",
        "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=dec_states)\n",
        "\n",
        "# Attention inference\n",
        "attention_result_inf, attention_weights_inf = attention_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_concat_input_inf = Concatenate(axis=-1, name='concat_layer')([decoder_outputs2, attention_result_inf])\n",
        "\n",
        "dec_states2= [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_concat_input_inf)\n",
        "\n",
        "# get decoder model\n",
        "decoder_model= Model(\n",
        "                    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_h, decoder_state_c],\n",
        "                     [decoder_outputs2]+ dec_states2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEi7Jc2pQcxR"
      },
      "outputs": [],
      "source": [
        "def get_predicted_sentence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    enc_output, enc_h, enc_c = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = As_word_index['s']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [enc_output, enc_h, enc_c], verbose=0)\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        # convert max index number to marathi word\n",
        "        sampled_char = As_index_word[sampled_token_index]\n",
        "        # append it to decoded sent\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length or find stop token.\n",
        "        if (sampled_char == 'e' or len(decoded_sentence.split()) >= 28):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        enc_h, enc_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RXyp39UQhEI",
        "outputId": "35cd08a8-a267-4884-a7c0-a9b8c01226aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question Sentence: how to steep but separate leaves in a teapot without a mesh strainer \n",
            "Actual Answer Sentence: s rather than using a strainer built into your teapot use an external strainer allow the hot water and loose tea leaves to hang out in your pot then pour through the strainer into your cup this one costs cdn on amazon ca i m sure you can find plenty in that price range slightly more expensive ones come with a little bowl to set them down in so as not to dribble on a counter e \n",
            "Predicted Answer Sentence:  i have a similar problem with a small amount of paper towel i ve had a few years ago and it s a little bit of a few\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: randomizing papers \n",
            "Actual Answer Sentence: s take a well shuffled deck of cards and paperclip a card to each one in turn then sort them into deck order a k spades followed by a k hearts a k diamonds a k clubs e \n",
            "Predicted Answer Sentence:  i have a similar problem by using a small amount of paper towel i have a similar problem with my fingers and i can t get a small\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: how can i improve air conditioning effectiveness in my old car \n",
            "Actual Answer Sentence: s check to see if all the r a leaks out meaning there s nothing in the loop to carry away heat make sure the compressor is turning the other sorts of problems that the ac might be experiencing include bad switches bad fuses broken wires broken fan belt preventing the pump from turning or seal failure inside the compressor if the system cools but not much it could just be low pressure and you can top up the refrigerant e \n",
            "Predicted Answer Sentence:  i have a similar problem with my fingers and i have a small hole in my experience and i have a small hole in my experience and i\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: how do i fold a fitted sheet \n",
            "Actual Answer Sentence: s no there isn t because the it s bigger on the inside a neat fold of these sheets will mean pushing the higher corner of the fold into the lower one on both corners so that although it s not flat the sheet will be symmetrical and fairly smooth once folded e \n",
            "Predicted Answer Sentence:  i have a similar problem with my own shirt but i have a small problem with my own shirt and i have a few sheets of my shirt\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: how to get rid of dandruff from hairs \n",
            "Actual Answer Sentence: s certain shampoos strip moisture from hair and i don t see anyone pointing out that the shampoo may be part of the issue head and shoulders is especially stripping of moisture though there are many offenders i can recommend a few shampoo conditioner sets that can help combat this dryness organix moraccan argon oil is a set really any organix product is a set three minute miracle deep conditioner by aussie loreal everpure conditioner any shampoos or conditioners formulated for deep moisture or wavy curly hair these can be purchased at any drugstore pharmacy using cold water can be less drying than hot water as well hair masks or oils can be good to but the true problem can probably be solved with any shampoo or conditioner listed above e \n",
            "Predicted Answer Sentence:  i ve had a similar problem with my hands in my experience and it s a little bit of a few days in the morning i have used\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: keeping sleep apnea mask on \n",
            "Actual Answer Sentence: s mittens might work you re probably removing it with your hands in your sleep rather than it just coming off but you need mittens without a thumb piece like the ones babies have when they keep scratching their faces so i m thinking maybe try wearing a pair of socks on your hands just to see if that stops you they need to be not too loose though and preferably of thick material to make it difficult to use your fingers individually e \n",
            "Predicted Answer Sentence:  the best way to do is to make a good problem with a small amount of light you can use a small piece of paper to make the\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: best way to know if somebody has broken into my room without camera \n",
            "Actual Answer Sentence: s my first answer would have been to tamper proof the door as well but i like this one too fill up a large bowl with an assortment of candy and leave it in your room while the contents of the bowl look random and uncounted you have in fact counted it s contents to enhance the plot share the candy with your roommates before you leave let them know that there is a huge bowl of candy in your possession and in the spirit of jimmy hoffa s answer poison the candy e \n",
            "Predicted Answer Sentence:  if you have a door door door door door door door door door door door door door door door door door door door door door door door door\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: where to put used but usable clothes a k a alternative to the chair \n",
            "Actual Answer Sentence: s the truth is that if your clothes are not clean enough to go back in your wardrobe they really need to go in the wash not on your chair for wearing again if you ve warn them and they re even slightly smelly or dirty then you really don t want to wear them again do you so wash them on the other hand if they re neither of those things they won t contaminate other things if they go back in with the clean stuff so do that it really is ok to put worn but clean stuff back in the drobe similarly if your garments are too crumpled to go back with the tidy stuff they re too crumpled to wear so press them again before putting them back now you might argue that some clothes will never get washed following this principle in practice this simply doesn t happen you can tell when clothes need washing i gave up my own chair about years ago and can attest that the wash or wardrobe method works well in practice in summary then i d say your challenge isn t to find a different resting place for half worn clothes but to see the problem differently clothes go back in the wardrobe or they go in the wash there really is no middle ground e \n",
            "Predicted Answer Sentence:  i have a similar problem with my head and i had a few years ago and it s a little bit of a few years ago i had\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: stay conscious and focused while driving \n",
            "Actual Answer Sentence: s my standard method is when i notice i am beginning to fall asleep i open a bag of very crunchy snacks corn nuts and eat one every seconds the stimulation of the crunching wakes up the brain and watching the digital clock for the one minute mark helps but as i drive and eat i also begin to look for a place where i can safely get off the road and take a nap this technique works for to minutes e \n",
            "Predicted Answer Sentence:  i have a similar problem by using a small amount of paper towel i have a similar problem with my fingers and i have a small hole in\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "Question Sentence: ways to stop your beach blanket from blowing away \n",
            "Actual Answer Sentence: s add loops to the corners of your blanket and then use plastic foot safe stakes to hold down each corner stakes are less likely to pull free in the wind than just tucking corners into the sand e \n",
            "Predicted Answer Sentence:  i have a similar problem with my shoes but i have a few years ago and it s a lot of a day and it s a little\n",
            "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# get the actual answer sentence\n",
        "def get_A_sentence(input_sequence):\n",
        "    sentence =''\n",
        "    for i in input_sequence:\n",
        "      if i!=0 :\n",
        "        sentence = sentence + As_index_word[i]+' '\n",
        "    return sentence\n",
        "\n",
        "# get the qeustion sentence\n",
        "def get_Q_sentence(input_sequence):\n",
        "    sentence =''\n",
        "    for i in input_sequence:\n",
        "      if i!=0:\n",
        "        sentence = sentence + Qs_index_word[i]+' '\n",
        "    return sentence\n",
        "\n",
        "# we will take 2 questions\n",
        "for i in np.random.randint(0, 90, size=10):\n",
        "  print(\"Question Sentence:\",get_Q_sentence(X_test[i]))\n",
        "  print(\"Actual Answer Sentence:\",get_A_sentence(y_test[i]))\n",
        "  # Before passing input it has to be reshape as following as the longest question was 28 tokens\n",
        "  print(\"Predicted Answer Sentence:\",get_predicted_sentence(X_test[i].reshape(1,28)))\n",
        "  print(\"---\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlt1Az93ya4V"
      },
      "source": [
        "We Need to train MORE ! LIKE MORE MORE !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QWwl-fWQlMx"
      },
      "source": [
        "# Trial-2\n",
        "# We will fine tune a GPT 2 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "Since we are retraining a model on new text, we need to download the GPT-2 model first.\n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80/P4 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "to load the old model weights and train for our available GPU time then saving the new model weights. And repeat!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgL99_ISUohy"
      },
      "outputs": [],
      "source": [
        "#drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6BJK6jZGWeu"
      },
      "outputs": [],
      "source": [
        "# this cell used to download the old data which resulted in a huge setback\n",
        "#!gdown \"1TmT0pJbt7Iid8ManwSJUu6ir6F6d0i9S\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5R8CyfJU02U",
        "outputId": "12994d92-f2ad-4661-beef-969c52f16627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnvvixTzpA2V"
      },
      "outputs": [],
      "source": [
        "# making the data in the right format this time\n",
        "df = pd.read_csv(\"/content/NLP_Data.csv\", index_col=0)\n",
        "Qs = df['Question']\n",
        "As = df['Answer']\n",
        "with open(\"New_Data.txt\",'w') as f:\n",
        "  for i in range(len(Qs)):\n",
        "    f.write(\"{}:{}\\n\".format(str(Qs[i]).strip(),\"\".join(str(As[i]).splitlines())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "outputs": [],
      "source": [
        "file_name = \"New_Data.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "## this note is taken from the original colab notebook (last link in the credits)\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ruDAjSAG_KO"
      },
      "outputs": [],
      "source": [
        "#! rm -r /content/checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9QWM6wtyhcl"
      },
      "outputs": [],
      "source": [
        "# get a copy from google drive to continue the training\n",
        "gpt2.copy_checkpoint_from_gdrive(run_name='GPT_2_TEST_RUN_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63qyeJIaY8y0"
      },
      "outputs": [],
      "source": [
        "sess = gpt2.start_tf_sess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeXshJM-Cuaf",
        "outputId": "2b1f6086-96e8-47be-8d5e-06237362a1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/GPT_2_TEST_RUN_2/model-27000\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 1/1 [00:05<00:00,  5.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 1282097 tokens\n",
            "Training...\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-27000\n",
            "======== SAMPLE 1 ========\n",
            " with the same number of uses? Then only one person can be doing the lighting work. \n",
            "How to restore white stain from LCD screens?:It appears that the display hardware has become too powerful. You may replace display.There are a variety of reactive finish for your screen, some chemical luminous inks from a drugstore are particularly good.I suggest special shielding for your screen (super weak) from restoring to good quality with a bond razor blade.\n",
            "How to restore white stain from LCD screens?:You can purchase non-gloss/transparent opticsorkers that apply to the screen instead of the screen marker. They don't have to be transparent, just matte black - and they can be painted transparent as well (see this video, @qnote: who wants to paint in front of a projector))This kind of resins has been used for industrial screens, such as those for projector glass. It's not very common now, but it deserves a digital to a (mostly) digital scale. \n",
            "How to restore white stain from LCD screens?:Apply a layer of activated charcoal. The charcoal emulates the charcoal that is placed on the surface of the stain. Similar to activated charcoal on LCDs, activated charcoal creates a crust that matches the screen texture and blends the remnants. It's not reactive but built-in to the screen and should correct the course of the screen when removed or turned off. Chrome activated charcoal is more permanent solution and easier to apply. Bonfire charcoal is designed to prevent white spots from recurring or appearing on black surfaces. Similar apps are available to remove gunk and adorn photos due to the gunk's adhesive nature. Similar reactive materials like activated charcoal can be used to prevent over- or under- sticking. Similar reactive materials are plexiglass, brick, and stainless steel all good solutions. Several antioxidants reduce such over- or under-smoothing stones.Similar reactive materials are pretty standard treatments for photogenic stones like stained glass and same color deposits on body and mind. Cyanoacrylate will often remove such over workshat surfaces. Cyanoacrylate is air-based so should be treated with a water wipe after application. It is formed from the brown oil-like chemistry of protein molecules. Similar solution also works as an oxygen fixing agent for paint  surfaces. Similar foam-based treatments repair eyes, ears, and skin damage. Oxygen and Vitamin C both heal. Similar reactive materials like activated charcoal, peate, and charcoal on white lime deposits help remove deposits of stains from photosensitive screens to viral looking ones.\n",
            "How to restore white stain from LCD screens?:Normal Resin and Charcoal have a pH of 4.4 and a life of manufacturing chemically reactive materials to resist changes in pH as they breakdown.Note: This is just a suggestion only; I have no experience with this particular material so if you or you5 know of someone using normal, phosphoric acid resins for non-photosensitive screens, I suggest you just try them.\n",
            "How to restore white stain from LCD screens?:Lysol is good for both cleaning and lubricating - if used with normal saline.In swabs kind, the blue. I've never felt weird pulling a lot of Lysol out of a syringe or even Lysol Pre-Seal, as I've never felt so awkward rubbing most of it on a surface.Unlike most Lysol Squash capsules, Lysol Lysol Lysol Lysol Lysol Lysol When I got these kind of capsules, and tried Lysol Lysol Lysol Lysol it made everything worse. \n",
            "How to clean transparent plastic bag?:A toothpick or needle is good.  Rub the seal bag with the toothpick and leave a whitish-toned toothpick or needle in it for 5-10 seconds to scrape away any bubbles and oil.After this, get another bag of Lysol, this time coated in mineral oil.  Do this step by step and through the reaction of Lysol with Alcohol to prevent the formation of oil.  The oils will easily separate from the Lysol and hang on as a set of instructions for good results.\n",
            "How to clean transparent plastic bag?:Personally, I have this trick which is pretty much any thin plastic bag with a small opening in the front for rubbing alcohol and rubbing powder onto the plastic bags. So,derickX\n",
            "How to clean transparent plastic bag?:I would try to buy a new plastic bag every few years or so. If you can, then I would recommend you to use a magnet (Magipino's answer) as it is quite cheap, as well as a new type of cleaning mat (I would not lifehome the same beat).  You might need this for different stages in the bag, and for each stage itself, you will discover a new shiny surface that works best.\n",
            "How to clean transparent plastic bag?:You can always try some bubble sprays:These work well, as long as you create a gap of gentle suction, and to a\n",
            "\n",
            "[27010 | 42.88] loss=0.32 avg=0.32\n",
            "[27020 | 65.92] loss=0.27 avg=0.29\n",
            "[27030 | 89.02] loss=0.31 avg=0.30\n",
            "[27040 | 111.77] loss=0.33 avg=0.31\n",
            "[27050 | 134.53] loss=0.30 avg=0.31\n",
            "[27060 | 157.53] loss=0.28 avg=0.30\n",
            "[27070 | 180.75] loss=0.28 avg=0.30\n",
            "[27080 | 203.95] loss=0.27 avg=0.30\n",
            "[27090 | 227.14] loss=0.31 avg=0.30\n",
            "[27100 | 250.33] loss=0.30 avg=0.30\n",
            "[27110 | 273.57] loss=0.28 avg=0.30\n",
            "[27120 | 296.80] loss=0.26 avg=0.29\n",
            "[27130 | 320.06] loss=0.26 avg=0.29\n",
            "[27140 | 343.30] loss=0.26 avg=0.29\n",
            "[27150 | 366.52] loss=0.26 avg=0.29\n",
            "[27160 | 389.72] loss=0.24 avg=0.28\n",
            "[27170 | 412.94] loss=0.25 avg=0.28\n",
            "[27180 | 436.15] loss=0.34 avg=0.28\n",
            "[27190 | 459.36] loss=0.49 avg=0.30\n",
            "[27200 | 482.54] loss=0.20 avg=0.29\n",
            "[27210 | 505.72] loss=0.27 avg=0.29\n",
            "[27220 | 528.92] loss=0.20 avg=0.29\n",
            "[27230 | 552.11] loss=0.32 avg=0.29\n",
            "[27240 | 575.29] loss=0.22 avg=0.28\n",
            "[27250 | 598.50] loss=0.28 avg=0.28\n",
            "[27260 | 621.69] loss=0.23 avg=0.28\n",
            "[27270 | 644.85] loss=0.25 avg=0.28\n",
            "[27280 | 668.03] loss=0.30 avg=0.28\n",
            "[27290 | 691.20] loss=0.28 avg=0.28\n",
            "[27300 | 714.41] loss=0.27 avg=0.28\n",
            "[27310 | 737.60] loss=0.29 avg=0.28\n",
            "[27320 | 760.77] loss=0.28 avg=0.28\n",
            "[27330 | 783.90] loss=0.31 avg=0.28\n",
            "[27340 | 807.12] loss=0.26 avg=0.28\n",
            "[27350 | 830.41] loss=0.32 avg=0.28\n",
            "[27360 | 853.58] loss=0.37 avg=0.28\n",
            "[27370 | 876.73] loss=0.23 avg=0.28\n",
            "[27380 | 899.84] loss=0.31 avg=0.28\n",
            "[27390 | 923.07] loss=0.33 avg=0.29\n",
            "[27400 | 946.37] loss=0.28 avg=0.29\n",
            "[27410 | 969.58] loss=0.24 avg=0.28\n",
            "[27420 | 992.75] loss=0.27 avg=0.28\n",
            "[27430 | 1015.89] loss=0.24 avg=0.28\n",
            "[27440 | 1039.11] loss=0.23 avg=0.28\n",
            "[27450 | 1062.37] loss=0.27 avg=0.28\n",
            "[27460 | 1085.58] loss=0.26 avg=0.28\n",
            "[27470 | 1108.77] loss=0.31 avg=0.28\n",
            "[27480 | 1131.92] loss=0.19 avg=0.28\n",
            "[27490 | 1155.08] loss=0.22 avg=0.28\n",
            "[27500 | 1178.31] loss=0.27 avg=0.28\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-27500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py:1066: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== SAMPLE 1 ========\n",
            "lf (in the US) which is far cheaper than the cheapest open wounds that are available in the general public. I do not know if this makes the wound worse or better, but every wound specialist agrees that having a good wound can improve effectiveness over time.I have not done a full assessment of the wound healing process, but the fact that I was able to get access to a small organisation and that I had the opportunity to play Magic for the first time in years tells you are many things. \n",
            "How to cut open loaf of bread?:Stick the teeth while bending the knees downward. Bending down that is forced forward on the bent legs. Update with a diagram that helps us orient match-wise and a something that helps us orient match-wise\n",
            "How to cut open loaf of bread?:Here's the normal way to open fennel / clove cases:Take a small bite, bled like magic. Then Put the rest in the pantyhose.Or, forget all the bread, all is milk.\n",
            "How to cut open loaf of bread?:Open a bread bin, so you can be sure that whoever eats that bread somehow got toasting it and is not seen getting full later on. Put the breads in a plastic bag or carry them in a (bundled) about June boxes. With a knife even the wings must be lifted back a little. It is said that in some breads left in (bundled with) bread also fresh water will be produced.\n",
            "How to cut open loaf of bread?:With a metal spoon, literally cut through the pan and slices across it's margin of splinters. Also saw it a day where it survived this method\n",
            "How to cut open loaf of bread?:With a rubber band, literally cut through the pan and slices across it's margin of splinters. Also saw it a day where it survived this method but wasnt able to it itself...\n",
            "Best glue to fix car door open?:While not every type of glue is right for life-changing effects (such as reactive oxygen species) it is a fact of life many cars glue is not strong enough to hold its own in the body any more than paint is strong enough: http://www.livestream.comrol\"\n",
            "Best glue to fix car door open?:We find that trying rubber bands will improve your car-life skills. For example, I used to just use glue boot salesperson Maggie for landscaping too, but if you drive along a patch of wood, you use the rubber band after you become used to its smell.But, I should suggest a tip: As the only good rubber left is the one in the glue business, Treat it as another compound your dealer's repairer's glue: Ammonia or another prostitutedil thinner\n",
            "Best glue to fix car door open?:Ever wondered why people forget that all things in a waxy coating are actually at least a little bit goopy?There are some typical types of wax that won't \"apply\" to a door or window if youlying the waxy stuff. On the upside this is also very good for auto- fixes as it gives the vehicle a new springy feel even if it has been dry and rough for a whileIf you remember that waxy things can \"tainting the appearance of a label, they could be from food or chemical names either 'waxy' or similarSoak the window with water in a mortar and pestle a tiny dot to make the labels come off easier'inatorially creating a layer of granulation based wax which will prevent the labels from re-wearing anything but clean'I found some original bottle stickers which can be a problem when doing the regular door-on liseatings.stacking. As well as the obvious work on your window you can do swatch or spray form a year with a fine spray until the problem is gone. The window sticker pattern can be stitched in to the normal bottle stickers into the underlying bottle labels.Fill up a 2l rubber fire mint tea and sewn them with a razor blade. An easy task and they're easily wrapped and put away before you need it. The fire tea will last a while and you can take them home and you can be sure they're getting new.Good luck\n",
            "Best glue to fix car door open?:Go with glue magazine or rubber band.Best off method is Terry porcupoeose or sand or elastomer.If you need too mucho sticky glue it is just as good to use on a tree or thing or than anybody could do that old rusty car window that always fell back. \n",
            "Any idea how to remove this build-up from glass shower door?:As for answering your question: As I've suggested in another answer, you could try in extra deep soapy water.Water is a-ok pretty good but certainly not good at removing all bad smells from surfaces. As I said before,naments may work to your advantage. After all, death's ail it and it\n",
            "\n",
            "[27510 | 1214.79] loss=0.27 avg=0.28\n",
            "[27520 | 1237.69] loss=0.28 avg=0.28\n",
            "[27530 | 1260.55] loss=0.25 avg=0.28\n",
            "[27540 | 1283.39] loss=0.32 avg=0.28\n",
            "[27550 | 1306.24] loss=0.27 avg=0.28\n",
            "[27560 | 1329.15] loss=0.30 avg=0.28\n",
            "[27570 | 1352.36] loss=0.31 avg=0.28\n",
            "[27580 | 1375.61] loss=0.28 avg=0.28\n",
            "[27590 | 1398.89] loss=0.32 avg=0.28\n",
            "[27600 | 1422.11] loss=0.26 avg=0.28\n",
            "[27610 | 1445.22] loss=0.38 avg=0.28\n",
            "[27620 | 1468.47] loss=0.17 avg=0.28\n",
            "[27630 | 1491.71] loss=0.29 avg=0.28\n",
            "[27640 | 1514.89] loss=0.29 avg=0.28\n",
            "[27650 | 1538.04] loss=0.28 avg=0.28\n",
            "[27660 | 1561.21] loss=0.25 avg=0.28\n",
            "[27670 | 1584.37] loss=0.28 avg=0.28\n",
            "[27680 | 1607.52] loss=0.23 avg=0.28\n",
            "[27690 | 1630.67] loss=0.23 avg=0.28\n",
            "[27700 | 1653.90] loss=0.27 avg=0.28\n",
            "[27710 | 1677.16] loss=0.27 avg=0.28\n",
            "[27720 | 1700.33] loss=0.21 avg=0.28\n",
            "[27730 | 1723.47] loss=0.34 avg=0.28\n",
            "[27740 | 1746.64] loss=0.29 avg=0.28\n",
            "[27750 | 1769.84] loss=0.29 avg=0.28\n",
            "[27760 | 1792.98] loss=0.24 avg=0.28\n",
            "[27770 | 1816.24] loss=0.26 avg=0.28\n",
            "[27780 | 1839.53] loss=0.33 avg=0.28\n",
            "[27790 | 1862.66] loss=0.24 avg=0.28\n",
            "[27800 | 1885.93] loss=0.31 avg=0.28\n",
            "[27810 | 1909.16] loss=0.30 avg=0.28\n",
            "[27820 | 1932.35] loss=0.18 avg=0.28\n",
            "[27830 | 1955.51] loss=0.22 avg=0.27\n",
            "[27840 | 1978.69] loss=0.28 avg=0.27\n",
            "[27850 | 2001.86] loss=0.24 avg=0.27\n",
            "[27860 | 2024.99] loss=0.30 avg=0.27\n",
            "[27870 | 2048.26] loss=0.33 avg=0.28\n",
            "[27880 | 2071.53] loss=0.26 avg=0.28\n",
            "[27890 | 2094.78] loss=0.27 avg=0.28\n",
            "[27900 | 2117.96] loss=0.26 avg=0.27\n",
            "[27910 | 2141.15] loss=0.25 avg=0.27\n",
            "[27920 | 2164.29] loss=0.27 avg=0.27\n",
            "[27930 | 2187.51] loss=0.22 avg=0.27\n",
            "[27940 | 2210.80] loss=0.22 avg=0.27\n",
            "[27950 | 2233.98] loss=0.18 avg=0.27\n",
            "[27960 | 2257.14] loss=0.29 avg=0.27\n",
            "[27970 | 2280.41] loss=0.29 avg=0.27\n",
            "[27980 | 2303.62] loss=0.29 avg=0.27\n",
            "[27990 | 2326.88] loss=0.28 avg=0.27\n",
            "[28000 | 2350.05] loss=0.25 avg=0.27\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-28000\n",
            "======== SAMPLE 1 ========\n",
            " of it.\n",
            "How do I clean plastic waste bags on the go?:I do that in my head! Now I put the dirty bags into a Ziploc bag, put the Ziploc in the plastic bag. Now when you open the bag the plastic bag end is caught in the Ziploc in the middle. Now the Ziploc with trash can is in the middle while the dirty bags go in the trash. Pressing the Ziploc with the bag end while squeezing the bags press the bag end harder while pulling. Vacuum cleaner works wonders. Cleaner will do the same. \n",
            "How do I clean plastic waste bags on the go?:I googled a lot and I found this answer that basically boils down to this:Get a better grasp on what's inside the trash bag. If you use:Stack up what you stack into a single bag (for example, a gallon of natural gas will be 2 stacked together, and you'll need a sack of trash).Count the bags that have just been disposed of. If you want to count all bags that have been disposed of.Put this all together. Then you have your \"Barack\" / \"Nicky\" Trap.If you use \"Wendell Workman\" \"It's not good to waste a jot of paper\"; this is a \"Scotchpot.\"Put them in alphabetical order.My trick is separating bags into separate bins. I've put together like a two-gallon bucket with a hose that has a bunch of air in it. The bags then go in to one huge bin for cleaning. That helps disperse the waste far.Put mattresses/bedrolls in the middle of the stack. That makes sure all bags are empty and cool. Put TV/3G data in a smaller bag, without placing too much drag on the UPS.I use this trick a lot. I've never really put labels on top of bags, because it makes it so easy to check on where the trash is. But for a \"Just For That\" In-Home Organization method, you have a lot more space. Just put a couple extra in (most) of the cardboard bags.\n",
            "How do I clean plastic bags on the go?:I use a trash brush which, while cumbersome, works even better in larger bags. As I said, where you want to rinse the plastic you can pack it into tiny ziplock bags or a washing machine. And the big gimlets, my personal experience is those that have rubber feet. And the plastic is clean, there is no dye or gunk getting in between it and paper and ink.\n",
            "How do I clean plastic bags on the go?:I googled \"cheese knife\" and \"cheese tongue\" and almost found the link worth much 3 seconds but worth a try!Use the cheese to grab the bags and keep it there! :)It's a really useful ability, and I use it a lot!\n",
            "How do I clean plastic bags on the go?:I googled \"cheese knife\", and was told that it is used in Thailand to remove bag skin. The video shows the action quickly!Here:https://www.wikihow.th/Cheese-Slash-Thai\n",
            "How do I clean plastic bags on the go?:I saw something on TV a while back called \"Golden Lick Spills\". It focuses on lip sticks and the flat surfaces they can with a quick wiping powder and you should speak with your local pharmacist for some stuffs on stopping the growth of lip sticks.I'm sure it's possible to get a hold of ac the like that you won't get in normal pharmacies? I've never used it to clean plastic products though, so they're probably fake. I've just heard that French supermarkets just gag me when I mention this, when I say such things as shopping there would stop these lip sticks from growling.\n",
            "How do I clean plastic bags on the go?:You need 70% alcohol. A duvet cover will do, if sleepy.The scrub looks like this:Since it contains lip sticks, you can \"scrub\" them dry by rubbing them on them. Start on the front and then on the back. I found that after a few trials and fancies how I watch with them after a long time, they won't leave the scrub stuck on my skin.\n",
            "How do I clean plastic bags on the go?:For someone who hates the messy, you could try:Try this: Killing time, putting a mildly acidic solution in the bag after you get to the bottom (soot) doesn't pollute the air either. But this is the worst chance I can think of, because the jelly will get on the boards and the jelly won't get on board.You can scrub the bag after aboard the jelly getting the best of you.but you can't the far right corner. This is the left side. This is the far right corner. I've tried this, and it\n",
            "\n",
            "[28010 | 2386.50] loss=0.23 avg=0.27\n",
            "[28020 | 2409.57] loss=0.20 avg=0.27\n",
            "[28030 | 2432.70] loss=0.28 avg=0.27\n",
            "[28040 | 2455.96] loss=0.32 avg=0.27\n",
            "[28050 | 2479.18] loss=0.26 avg=0.27\n",
            "[28060 | 2502.39] loss=0.26 avg=0.27\n",
            "[28070 | 2525.59] loss=0.23 avg=0.27\n",
            "[28080 | 2548.77] loss=0.23 avg=0.27\n",
            "[28090 | 2571.95] loss=0.32 avg=0.27\n",
            "[28100 | 2595.11] loss=0.26 avg=0.27\n",
            "[28110 | 2618.37] loss=0.29 avg=0.27\n",
            "[28120 | 2641.60] loss=0.28 avg=0.27\n",
            "[28130 | 2664.77] loss=0.25 avg=0.27\n",
            "[28140 | 2688.02] loss=0.24 avg=0.27\n",
            "[28150 | 2711.29] loss=0.26 avg=0.27\n",
            "[28160 | 2734.52] loss=0.26 avg=0.27\n",
            "[28170 | 2757.75] loss=0.24 avg=0.27\n",
            "[28180 | 2780.95] loss=0.19 avg=0.27\n",
            "[28190 | 2804.10] loss=0.28 avg=0.27\n",
            "[28200 | 2827.30] loss=0.25 avg=0.27\n",
            "[28210 | 2850.58] loss=0.28 avg=0.27\n",
            "[28220 | 2873.83] loss=0.27 avg=0.27\n",
            "[28230 | 2897.04] loss=0.31 avg=0.27\n",
            "[28240 | 2920.25] loss=0.30 avg=0.27\n",
            "[28250 | 2943.43] loss=0.33 avg=0.27\n",
            "[28260 | 2966.61] loss=0.25 avg=0.27\n",
            "[28270 | 2989.78] loss=0.31 avg=0.27\n",
            "[28280 | 3012.97] loss=0.31 avg=0.27\n",
            "[28290 | 3036.15] loss=0.27 avg=0.27\n",
            "[28300 | 3059.32] loss=0.22 avg=0.27\n",
            "[28310 | 3082.49] loss=0.31 avg=0.27\n",
            "[28320 | 3105.69] loss=0.23 avg=0.27\n",
            "[28330 | 3128.88] loss=0.23 avg=0.27\n",
            "[28340 | 3152.05] loss=0.22 avg=0.27\n",
            "[28350 | 3175.25] loss=0.26 avg=0.27\n",
            "[28360 | 3198.44] loss=0.27 avg=0.27\n",
            "[28370 | 3221.67] loss=0.20 avg=0.27\n",
            "[28380 | 3244.87] loss=0.29 avg=0.27\n",
            "[28390 | 3268.09] loss=0.27 avg=0.27\n",
            "[28400 | 3291.29] loss=0.27 avg=0.27\n",
            "[28410 | 3314.52] loss=0.24 avg=0.27\n",
            "[28420 | 3337.74] loss=0.29 avg=0.27\n",
            "[28430 | 3360.95] loss=0.29 avg=0.27\n",
            "[28440 | 3384.15] loss=0.25 avg=0.27\n",
            "[28450 | 3407.36] loss=0.19 avg=0.27\n",
            "[28460 | 3430.61] loss=0.26 avg=0.27\n",
            "[28470 | 3453.84] loss=0.24 avg=0.27\n",
            "[28480 | 3477.09] loss=0.25 avg=0.27\n",
            "[28490 | 3500.33] loss=0.28 avg=0.27\n",
            "[28500 | 3523.56] loss=0.27 avg=0.27\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-28500\n",
            "======== SAMPLE 1 ========\n",
            ". You need to allow the hair to dry, but not dry in the way of a dry hair dryer will.\n",
            "How do I keep a headphone wire from running free from my phone?:If you have some plastic case (not ear cases!) you could modeling-book-:Let the wire be a metal part in a metal channel. Then, you can have anything you like. Glass, metal, anything that has a cap.If the wire is wrapped around a battery or in an earpiece, for example, you have an answer.If it's an audio jack, you have a solution. Youll need to install modeling-book- knowledge base to sell these designs.If you have no prior exposure to finished designs, or no existing knowledge of headphone designs, Im guessing you want a modeling-book table toexplore.Even then, yout only want something that works and something that works well; obviously, if youve done nothing else with finished products its a chance to find out if its ever going to work.This doesnt solve the problem, but its an easy discovery.If you get free samples in layouts that arent perfect, yout probably going to get some custom treatment to close out the deal. This isnt really a design problem (unless it's a molar to crossbar).This is an issue because I had a clear answer that I want a modeling base.\n",
            "How do I keep a headphone wire from running free of plastic cases?:In your case, with the headphones closed?Wrap some Blu-tak on the bottom of your headphones and listen for any kind of plastic questions. If you don't get some, you probably won't get an answer.There are dozens of them out there. Ask anything from electronics to plumbing or carpeting.\n",
            "How do I keep a headphone wire from running free of plastic cases?:In case of simple corrosive product (plastic was my limiting factor in my being a wood shaver), we can say (as if conscious of past experience) that the tip has run free of the 'abrasion'.This treatment avoids being too viscous.\n",
            "How can I clean dust uparded petroleum drinks?:Try using of rubbing alcohol on the affected area (it's called the \"Head Refilling\" line in oxy alcohol, Incircling Oil) rubbed on a clean, dry cloth or paper towel over a relatively flat area. Do not scrub the area thoroughly, or it will drip all over it.This will help at least for a few hours.\n",
            "How can I clean dust uparded petroleum drinks?:Any of those's it will take, but I've always just lit an incense as my stove.\n",
            "How can I clean dust uparded petroleum drinks?:Liquids will rapidly become incandescent when converted to gas when exposed to benzene. If you have benzene holdersit, slowly slow down the lighters, one at a time.Take one ahead of the following two,cancel down and slow the down, go over the holder, refill, and pop it back in to fill.\n",
            "How can I clean dust uparded petroleum drinks?:The incense that you mention are most likely to halve in temperature when exposed to benzene. If you look at the chemical composition of benzene, you'll see that it is in the carbon in them. All the ones that I can think of would be most in the carbon of the atoms. As a final measure I'll add a bit of benzene to my battery spray, as it's in the 4:2:\n",
            "How can I clean dust uparded petroleum drinks?:Fe2 odor will not build up so quickly in crude oil (its fizzing, reducing flavour).\n",
            "How can I clean dust uparded petroleum drinks?:You can use a sponge/toothpaste roll, or a rubber band to clean the sponge and to remove any remaining crud. \n",
            "How to remove grease from monitor with grill set with grill:I don't like using a grill, as that's how I do my business. However, if you get enough of that, you can quickly clean the grill even while doing other things. You'll want to get some kind of plastic or glass that's thin enough that won't scratch when you're doing it above water - like a sandwich, discarding the scratch simply from the surface.If you don't have a plastic or glass, you can dab a bit of paper towel or Styrofoam board or whatever on the grease just before it builds up so it won't redden with the grill. This will greatly reduce the likelihood of a grease spill.\n",
            "How to remove grease from monitor with grill set with grill:If your monitor comes\n",
            "\n",
            "[28510 | 3561.16] loss=0.26 avg=0.27\n",
            "[28520 | 3584.39] loss=0.28 avg=0.27\n",
            "[28530 | 3607.57] loss=0.21 avg=0.27\n",
            "[28540 | 3630.73] loss=0.23 avg=0.27\n",
            "[28550 | 3653.94] loss=0.22 avg=0.27\n",
            "[28560 | 3677.19] loss=0.27 avg=0.27\n",
            "[28570 | 3700.44] loss=0.30 avg=0.27\n",
            "[28580 | 3723.61] loss=0.28 avg=0.27\n",
            "[28590 | 3746.75] loss=0.23 avg=0.27\n",
            "[28600 | 3769.92] loss=0.21 avg=0.26\n",
            "[28610 | 3793.19] loss=0.33 avg=0.27\n",
            "[28620 | 3816.48] loss=0.24 avg=0.27\n",
            "[28630 | 3839.75] loss=0.32 avg=0.27\n",
            "[28640 | 3863.01] loss=0.26 avg=0.27\n",
            "[28650 | 3886.27] loss=0.30 avg=0.27\n",
            "[28660 | 3909.50] loss=0.28 avg=0.27\n",
            "[28670 | 3932.74] loss=0.22 avg=0.27\n",
            "[28680 | 3955.94] loss=0.25 avg=0.27\n",
            "[28690 | 3979.14] loss=0.26 avg=0.27\n",
            "[28700 | 4002.31] loss=0.23 avg=0.27\n",
            "[28710 | 4025.48] loss=0.19 avg=0.26\n",
            "[28720 | 4048.65] loss=0.25 avg=0.26\n",
            "[28730 | 4071.84] loss=0.24 avg=0.26\n",
            "[28740 | 4095.07] loss=0.30 avg=0.26\n",
            "[28750 | 4118.30] loss=0.20 avg=0.26\n",
            "[28760 | 4141.54] loss=0.32 avg=0.26\n",
            "[28770 | 4164.78] loss=0.22 avg=0.26\n",
            "[28780 | 4188.05] loss=0.21 avg=0.26\n",
            "[28790 | 4211.30] loss=0.23 avg=0.26\n",
            "[28800 | 4234.53] loss=0.31 avg=0.26\n",
            "[28810 | 4257.73] loss=0.23 avg=0.26\n",
            "[28820 | 4280.95] loss=0.25 avg=0.26\n",
            "[28830 | 4304.16] loss=0.23 avg=0.26\n",
            "[28840 | 4327.35] loss=0.22 avg=0.26\n",
            "[28850 | 4350.53] loss=0.22 avg=0.26\n",
            "[28860 | 4373.71] loss=0.24 avg=0.26\n",
            "[28870 | 4396.90] loss=0.26 avg=0.26\n",
            "[28880 | 4420.12] loss=0.19 avg=0.26\n",
            "[28890 | 4443.37] loss=0.25 avg=0.26\n",
            "[28900 | 4466.62] loss=0.28 avg=0.26\n",
            "[28910 | 4489.87] loss=0.25 avg=0.26\n",
            "[28920 | 4513.12] loss=0.25 avg=0.26\n",
            "[28930 | 4536.33] loss=0.19 avg=0.26\n",
            "[28940 | 4559.53] loss=0.20 avg=0.26\n",
            "[28950 | 4582.71] loss=0.25 avg=0.26\n",
            "[28960 | 4605.87] loss=0.27 avg=0.26\n",
            "[28970 | 4629.06] loss=0.23 avg=0.26\n",
            "[28980 | 4652.25] loss=0.26 avg=0.26\n",
            "[28990 | 4675.44] loss=0.29 avg=0.26\n",
            "[29000 | 4698.61] loss=0.26 avg=0.26\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-29000\n",
            "======== SAMPLE 1 ========\n",
            " a longer stick. (The smaller ones won't be as thin, so it can move faster.) I usually do the cooking with the sticks, without draining it.If you use too many, the ice cubes may freeze and thaw as they become used, but the plastic of the glass won't become as stiff as the plastic of the ice cubes. And, this is even if you get rid of the ice cubes after rinsing the glass, you don't have to \"cleans\" the whole glass again. (And, I do mean \"cleaned\": Spray the glass with Ziplock baggies.)\n",
            "How to keep long hair clean?:Wash it in vegetable puree in little ice cubes and then place in a vacuum sealed container for to large volume. This way you are protecting the hair from dirt/frost damage.\n",
            "How to wash your rubber shoes when dry?:Mix a cup of sugar and a quarter cup of water in a ice cube. (We make our own so I'm not a shoe washing expert) This will mix enough sugar to make a sweet sugary mix. Just make it very cold to avoid the water boiling. You can pour the water into a spray bottle to make cold spray to distribute to the sponge applied to the dry.The solution that makes this problem disappear, is to make the solution so the hairs dry, that they are, in our opinion, dry again.When I say \"hanky panky\", I not trying to be crude. The problem is that you overmixing sugar/sugar so they are dry at the ends of the fingers. Also try to keep as much moisture on the fingers as possible.I recommend you to wash all your rubber shoes, place them in the freezer and thoroughly vacuum the place where you want to dry. Take the shoes and lay them out in a vacuum freezer. The moisture in the shoes will stop the molecules ending there from connecting with the shoes. Also make sure to reheat the shoes and dry them again in the vacuum freezer.Toilet paper is a good alternative, and if you are a laundry guy, it's useful for drying clothes, too.\n",
            "How to wash your rubber shoes when dry?:Humidity/Humidity/Humidity/Humidity!I have been drying rubber boots in the back yard with a rice brush for two years and it has dried remarkably well. The only two hairy spots I've had to posting anything this year are when tucking into the shoes, where some hairs just stick to the rims and stand on their edges.Having tried most pump and Rain-X, X washes off in a spray bottle. That being said, I have a few hundred grams in the front yard. If I have to use a dry brush, mill about modifier and rub it into the damp shoe like a dry brush. It takes only a few minutes a year to dry shoes of any type. If you use a brush on the work boots, do it first and then wet it with the water, so do wait to get the last particles off. If you are a dry-brushing and lightly rubbing, I would advise wiping the front and forth with the brush. Not a good solution since there is plenty of water to rid the bristles before the shoes become dry but it also leaves a lot of water to wet the shoes down with. If you have to use the dry/dry touch, toss the shoes off. If you have the dry-brush thing, well, well, well, well, well, it kind of starts to look like a messy grow up. The problem with the dry-brushing is that it doesn't clean the leather. The problem with the dry/dry leather cleaning machine is that it produces a lot of bubbles in the rubber, so I don't use. I just use a very small amount of slightly wet rubbing alcohol to get the soap down my fingers, grab the bubbles with the alcohol and leave them to work. \n",
            "How to dry shoes quickly?:With modern dry-brushing equipment, you can get rid of the problem quickly.  I recommend small amounts of baby powder or a normal, distilled drink designed for dry bracing.  If you don't have small enough brushes, you can drier water.  If you don't have large brushes, you can also use a dry-brush but instead run the water over a longer period of time.  You can also use a boom cloth designed to dry a smaller area, as a drying cloth.\n",
            "How to dry shoes quickly?:Consider a splash of water on the back of the shoes only when they are dry, clean, and no water marks or remnants of use. The \"repellant\" in this case is not actually used in shoes, but in a fabriciser like shower curtains or flooring cover (possibly called a \"silk bed\" or \"silk goy\") that you (or your spouse, if you are not married, has lying around).The fabriciser in this case is made of synthetic material; it\n",
            "\n",
            "[29010 | 4735.22] loss=0.24 avg=0.26\n",
            "[29020 | 4758.47] loss=0.23 avg=0.26\n",
            "[29030 | 4781.67] loss=0.19 avg=0.26\n",
            "[29040 | 4804.87] loss=0.24 avg=0.26\n",
            "[29050 | 4828.06] loss=0.26 avg=0.26\n",
            "[29060 | 4851.25] loss=0.26 avg=0.26\n",
            "[29070 | 4874.44] loss=0.22 avg=0.26\n",
            "[29080 | 4897.62] loss=0.28 avg=0.26\n",
            "[29090 | 4920.79] loss=0.15 avg=0.26\n",
            "[29100 | 4943.96] loss=0.26 avg=0.26\n",
            "[29110 | 4967.12] loss=0.25 avg=0.26\n",
            "[29120 | 4990.24] loss=0.23 avg=0.26\n",
            "[29130 | 5013.39] loss=0.21 avg=0.25\n",
            "[29140 | 5036.64] loss=0.25 avg=0.25\n",
            "[29150 | 5059.89] loss=0.27 avg=0.26\n",
            "[29160 | 5083.11] loss=0.26 avg=0.26\n",
            "[29170 | 5106.26] loss=0.26 avg=0.26\n",
            "[29180 | 5129.41] loss=0.20 avg=0.25\n",
            "[29190 | 5152.57] loss=0.22 avg=0.25\n",
            "[29200 | 5175.74] loss=0.22 avg=0.25\n",
            "[29210 | 5198.93] loss=0.19 avg=0.25\n",
            "[29220 | 5222.15] loss=0.32 avg=0.25\n",
            "[29230 | 5245.40] loss=0.28 avg=0.25\n",
            "[29240 | 5268.66] loss=0.27 avg=0.25\n",
            "[29250 | 5291.88] loss=0.21 avg=0.25\n",
            "[29260 | 5315.05] loss=0.21 avg=0.25\n",
            "[29270 | 5338.19] loss=0.26 avg=0.25\n",
            "[29280 | 5361.36] loss=0.19 avg=0.25\n",
            "[29290 | 5384.58] loss=0.25 avg=0.25\n",
            "[29300 | 5407.83] loss=0.25 avg=0.25\n",
            "[29310 | 5431.03] loss=0.24 avg=0.25\n",
            "[29320 | 5454.22] loss=0.26 avg=0.25\n",
            "[29330 | 5477.36] loss=0.21 avg=0.25\n",
            "[29340 | 5500.50] loss=0.21 avg=0.25\n",
            "[29350 | 5523.75] loss=0.19 avg=0.25\n",
            "[29360 | 5546.99] loss=0.26 avg=0.25\n",
            "[29370 | 5570.24] loss=0.23 avg=0.25\n",
            "[29380 | 5593.46] loss=0.24 avg=0.25\n",
            "[29390 | 5616.68] loss=0.26 avg=0.25\n",
            "[29400 | 5639.91] loss=0.24 avg=0.25\n",
            "[29410 | 5663.11] loss=0.26 avg=0.25\n",
            "[29420 | 5686.33] loss=0.21 avg=0.25\n",
            "[29430 | 5709.55] loss=0.24 avg=0.25\n",
            "[29440 | 5732.76] loss=0.27 avg=0.25\n",
            "[29450 | 5755.99] loss=0.22 avg=0.25\n",
            "[29460 | 5779.17] loss=0.21 avg=0.25\n",
            "[29470 | 5802.40] loss=0.22 avg=0.25\n",
            "[29480 | 5825.62] loss=0.21 avg=0.25\n",
            "[29490 | 5848.82] loss=0.25 avg=0.25\n",
            "[29500 | 5872.02] loss=0.23 avg=0.25\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-29500\n",
            "======== SAMPLE 1 ========\n",
            " almost two cups). If you put the container in direct contact with the paper you can increase the air circulation quicker and have less paper smudges.To avoid your notebook getting wet, try to use a dry, pointy object such as a cloth or rag (a kettles cloth from a takeaway, say) instead of sticky or wet cloths that will cling to the paper. If you don't have a space that can be touched by the tweezers, give them a chance.Using hair drier is also a possible solution which is more convenient if you can find one. Consider setting the headlight to a long range and turning the headlight on its axis to better mirror the brightness of surrounding air (out of the distance something as remote as yourself rather than yourself inside the headlamp)Sound: Rock 'n roll bass players would also get working with a small horn 'n' HF guitar in the background, near the computer monitor and amp to improve echo. Vocal speakers could also play bass or a similar instrument. Using wooden blocks of wood with small holes to improve sound quality and increase bass playing (I am not sure of another type of 'chair')Can you buy a Ninja Billi with a couple of screw holes and a little string inserted? Ninja Billi with string Insert:\n",
            "Best way to get music out of the speakers of a monitor:In my experience, carrying sensitive music over longer distances is much easier than using headphones. Simply placing the music-drums on top of the speakers improves effective range and volume as well as reducing/ avoiding fx. \n",
            "How can I listen to music while running, or standing in the rain?:I would recommend the following:Use a hotel security manilla cord to your music that connects to your car's rain/shelf suspension (it should be 7 to 16 feet, a foot short of the actual car). Tie the end off to a cable then a paper clip to your car. Use the cable to go about 2 feet out of the way of wind, direct (your passenger) driver, and storm. Alternatively, keep the cord on top of the car's roof to prevent the air from escaping inside (breaking) the chord. Then, if you want a little more atmosphere, wrap the cord around the front of your car and blast some lense on the wind, keep tuned to iMessage for when the storm is over. :)\n",
            "How can I listen to music while running, or standing in the rain?:There a few simple options I can do, entwine with three: \n",
            "How can I listen to music while running, or standing in the rain?:Ensure you have the best headphones you can have.  My university place kept very much a Sony headphones, with excellent sound, but they had drops in the cables when use they were plastic; we had to pay for headphones made for music; expect it, but it is usually less than less.An oldathantha's answer is the best (and cheapest) source I could find for talking about what to look out for when buying headphones. As always, advise will be thanks.\n",
            "How to keep your eyes from getting cold when wearing headlamps:As you can see in the answer by some other commenters, finding the day lamp is warm enough is difficult.I found several solutions.First, three ballpoint pens worked miracles for the task of zig zag locating the day lamp.Second, a gel pen pen worked even better for cold reading. In colder days I used it to make a small thin tip way, and sometimes it worked like fire. Also, take care not to damage pen or ink. One pen always with a label like notice cause they can break if you aren't careful.\n",
            "Squeaking sneakers:Dab the sneeze into the shoe string. With some practise, you will make the string indestructible, but at least from dissolving into the ground. \n",
            "How to prevent headphones from squishing my tracks in your lap?:Not completely clear from this video if it was edited or not, but Micah is wearing glasses in this video. And Micah wears glasses whenever Micah plays - so it seems to be said the track cannot be smeared. The point is, you can't know if it gets or loses a peice until the microphone is in your pocket.The only thing I could suggest is to be able to see it, and see \"as if it were something else\". ie the tracking device. That allows you to have a \"paraphrasing\" reality instead of having a jarring \"surprised child\" episode.The track can be caught by rolling the field of vision rear-view mirror 25 deg. turns corona from your eyes. It'll be less reflective than your mirrors, so it should be nicely out of your way.To adjust your vision, by spinning your vision device, on the curved line with the mirror.\n",
            "How to keep sneakers from poppin' on the floor?:The foam of the trainers makes wiping\n",
            "\n",
            "[29510 | 5908.62] loss=0.20 avg=0.25\n",
            "[29520 | 5931.79] loss=0.19 avg=0.25\n",
            "[29530 | 5954.98] loss=0.22 avg=0.25\n",
            "[29540 | 5978.19] loss=0.17 avg=0.25\n",
            "[29550 | 6001.43] loss=0.24 avg=0.25\n",
            "[29560 | 6024.66] loss=0.21 avg=0.25\n",
            "[29570 | 6047.88] loss=0.21 avg=0.25\n",
            "[29580 | 6071.07] loss=0.28 avg=0.25\n",
            "[29590 | 6094.23] loss=0.22 avg=0.25\n",
            "[29600 | 6117.39] loss=0.28 avg=0.25\n",
            "[29610 | 6140.59] loss=0.25 avg=0.25\n",
            "[29620 | 6163.79] loss=0.24 avg=0.25\n",
            "[29630 | 6186.99] loss=0.21 avg=0.25\n",
            "[29640 | 6210.20] loss=0.24 avg=0.25\n",
            "[29650 | 6233.45] loss=0.22 avg=0.25\n",
            "[29660 | 6256.68] loss=0.24 avg=0.25\n",
            "[29670 | 6279.88] loss=0.24 avg=0.25\n",
            "[29680 | 6303.09] loss=0.22 avg=0.25\n",
            "[29690 | 6326.29] loss=0.23 avg=0.24\n",
            "[29700 | 6349.49] loss=0.31 avg=0.25\n",
            "[29710 | 6372.69] loss=0.28 avg=0.25\n",
            "[29720 | 6395.90] loss=0.23 avg=0.25\n",
            "[29730 | 6419.07] loss=0.22 avg=0.25\n",
            "[29740 | 6442.28] loss=0.23 avg=0.25\n",
            "[29750 | 6465.49] loss=0.24 avg=0.25\n",
            "[29760 | 6488.67] loss=0.23 avg=0.25\n",
            "[29770 | 6511.87] loss=0.19 avg=0.24\n",
            "[29780 | 6535.06] loss=0.17 avg=0.24\n",
            "[29790 | 6558.24] loss=0.22 avg=0.24\n",
            "[29800 | 6581.44] loss=0.21 avg=0.24\n",
            "[29810 | 6604.62] loss=0.23 avg=0.24\n",
            "[29820 | 6627.80] loss=0.24 avg=0.24\n",
            "[29830 | 6650.96] loss=0.23 avg=0.24\n",
            "[29840 | 6674.15] loss=0.22 avg=0.24\n",
            "[29850 | 6697.36] loss=0.17 avg=0.24\n",
            "[29860 | 6720.53] loss=0.23 avg=0.24\n",
            "[29870 | 6743.69] loss=0.23 avg=0.24\n",
            "[29880 | 6766.89] loss=0.19 avg=0.24\n",
            "[29890 | 6790.10] loss=0.24 avg=0.24\n",
            "[29900 | 6813.28] loss=0.24 avg=0.24\n",
            "[29910 | 6836.49] loss=0.21 avg=0.24\n",
            "[29920 | 6859.71] loss=0.23 avg=0.24\n",
            "[29930 | 6882.91] loss=0.21 avg=0.24\n",
            "[29940 | 6906.10] loss=0.23 avg=0.24\n",
            "[29950 | 6929.31] loss=0.23 avg=0.24\n",
            "[29960 | 6952.51] loss=0.17 avg=0.24\n",
            "[29970 | 6975.70] loss=0.18 avg=0.24\n",
            "[29980 | 6998.88] loss=0.19 avg=0.24\n",
            "[29990 | 7022.07] loss=0.21 avg=0.24\n",
            "[30000 | 7045.26] loss=0.26 avg=0.24\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-30000\n",
            "======== SAMPLE 1 ========\n",
            " I want to buy a new one. Maybe even one that works well for one of your items.\n",
            "Any way I can get cut my nails looks worst when I'm about to start washout. Any solutions or suggestions?:Use elbow greaseEat almonds and lavender during your washout. Rub using lavender. If you rub lavender into a bowl use the bottom of it as a rinse cloth. Then use Rub bar dish by you way are usually in a canal clean the rest of the items of clothing before removing the bag from yourtabletop.Then use Remove cleaner from a drawerrip out the bottom of your laundry bag. And start rubbing directly into the sockets of yourdedicated nail salon bags.\n",
            "Any way I can get cut my nails looks worst when I'm about to start washout. Any way I can use is to help set up a towel in the kitchen sink. When you get to the sink, pull a sliced apple (or any animal-looking type of fruit) one at a time (at a time) and rub it into the cut side of the sink. The sharp edges should be pressing into the bottom of your nails, while pushing all of the air out. After that, Bite back!Be careful not. It won't work when you're trying to push all the air out. It's a quick way of putting a permanent cut in the side of your nail.\n",
            "Any way I can get cut my nails looks worse when I'm about to start washout. A different, much better solution: just eat lunch early. Or, don't eat, wear a new dress. Or, maybe most importantly, eat notje which is made for the nails, but the waist. Either way, your nails will be more fitted and flatter than when you get the mass Control swab, and should work much better in letting the chemical wash out give and take. Maybe you mess up after a few weeks though, so how about a few uses and tweaking? Have you tried using a form of heat which on its own does not not not not damage organs many times over? First of all, any chemical to damage one organ will also to destroy another. If you are close to one of the dead cells, use a smaller amount developing that way Wrist Club, instead of the larger object, because, as J. F. Mello noted in The Problem With Organisms, most cell types have \"fundone\" components, which react with chemical reactions and cause pain.  It is not very likely for very long that one will develop pain giving bacteria and viruses. Instead, you could treat muscles, elimination, and tugs. If you develop pain developing two ways of thinking may help you get through the experiments. 1.1.1 You can get the chemical from a source other than eating lunch. You can get the chemical from the food. If none of the above applies, this analysis may be useful. If any of the above does not apply, at least it is possible to defeat the experiment. The purpose of this process is to check if using chemical in a drug that involves pain finding its source and becoming aware of possible painful sites being found.\n",
            "Any hack to unblock army surplus clothes with a simple solution to them notifier:I had 2 choices:Continue to recommend. To keep my issue under control, I am adding a garment notifier in my pocket. I got mine from an item selection box at my local Amazon. I have a ruler and their notifiers notifiers notifiers box. I just want them to match because I hate having too easily not-so-safe rulers. On a long line my daughters do not like neighbors deciding they are ugly or too hairy. So instead of having a ruler on my desk, I just have my rulers notifiers put into my pocket.To get them looking as good as possible, I put colour notifiers into some white cotton shirts. After a few weeks, they are quite unhappy with the shirt detail. So I add invisible labels on whites and add to the colours on the shirts - very nicely. The shirts are visibly identifiable. I have ordered 3 printer notifiers for my customer service. They were very pleased with the shirts. After the orders were placed, I take them to my local button down and print out the notifiers. The colour labels read \"UNDO TREGUE\". Very pleased.UTF-8, 8 mil colorful by noon UK (1700 kph).Followed several other methods with same results.I'm adding labels but not losing volume. I'm trying different methods as well. I'm not trying to be ugly or ugly-awfully. I'm just impressed.By successful methods, I have achieved undetectable proof that evil does indeed indeed exist. I'm adding 1 label for each collar and size. If you want proof, look no further. If you want invisibly true proof, consider investing in a collar transcender. All of the links are purchased with in their mission or purpose. The links are cheap\n",
            "\n",
            "[30010 | 7082.65] loss=0.22 avg=0.24\n",
            "[30020 | 7105.54] loss=0.18 avg=0.24\n",
            "[30030 | 7128.37] loss=0.27 avg=0.24\n",
            "[30040 | 7151.22] loss=0.21 avg=0.24\n",
            "[30050 | 7174.01] loss=0.26 avg=0.24\n",
            "[30060 | 7196.84] loss=0.23 avg=0.24\n",
            "[30070 | 7219.67] loss=0.25 avg=0.24\n",
            "[30080 | 7242.54] loss=0.17 avg=0.24\n",
            "[30090 | 7265.44] loss=0.26 avg=0.24\n",
            "[30100 | 7288.33] loss=0.22 avg=0.24\n",
            "[30110 | 7311.24] loss=0.19 avg=0.24\n",
            "[30120 | 7334.13] loss=0.23 avg=0.24\n",
            "[30130 | 7357.03] loss=0.16 avg=0.24\n",
            "[30140 | 7379.94] loss=0.22 avg=0.24\n",
            "[30150 | 7403.11] loss=0.13 avg=0.23\n",
            "[30160 | 7426.27] loss=0.20 avg=0.23\n",
            "[30170 | 7449.42] loss=0.23 avg=0.23\n",
            "[30180 | 7472.57] loss=0.20 avg=0.23\n",
            "[30190 | 7495.75] loss=0.21 avg=0.23\n",
            "[30200 | 7518.94] loss=0.17 avg=0.23\n",
            "[30210 | 7542.17] loss=0.19 avg=0.23\n",
            "[30220 | 7565.42] loss=0.23 avg=0.23\n",
            "[30230 | 7588.63] loss=0.26 avg=0.23\n",
            "[30240 | 7611.83] loss=0.25 avg=0.23\n",
            "[30250 | 7635.02] loss=0.25 avg=0.23\n",
            "[30260 | 7658.21] loss=0.21 avg=0.23\n",
            "[30270 | 7681.40] loss=0.29 avg=0.23\n",
            "[30280 | 7704.60] loss=0.25 avg=0.23\n",
            "[30290 | 7727.79] loss=0.21 avg=0.23\n",
            "[30300 | 7750.98] loss=0.24 avg=0.23\n",
            "[30310 | 7774.19] loss=0.23 avg=0.23\n",
            "[30320 | 7797.40] loss=0.21 avg=0.23\n",
            "[30330 | 7820.61] loss=0.18 avg=0.23\n",
            "[30340 | 7843.80] loss=0.21 avg=0.23\n",
            "[30350 | 7866.99] loss=0.18 avg=0.23\n",
            "[30360 | 7890.21] loss=0.21 avg=0.23\n",
            "[30370 | 7913.41] loss=0.21 avg=0.23\n",
            "[30380 | 7936.64] loss=0.21 avg=0.23\n",
            "[30390 | 7959.84] loss=0.22 avg=0.23\n",
            "[30400 | 7983.03] loss=0.23 avg=0.23\n",
            "[30410 | 8006.23] loss=0.19 avg=0.23\n",
            "[30420 | 8029.41] loss=0.25 avg=0.23\n",
            "[30430 | 8052.59] loss=0.19 avg=0.23\n",
            "[30440 | 8075.78] loss=0.25 avg=0.23\n",
            "[30450 | 8098.96] loss=0.21 avg=0.23\n",
            "[30460 | 8122.14] loss=0.20 avg=0.23\n",
            "[30470 | 8145.36] loss=0.21 avg=0.23\n",
            "[30480 | 8168.58] loss=0.20 avg=0.23\n",
            "[30490 | 8191.80] loss=0.19 avg=0.23\n",
            "[30500 | 8215.01] loss=0.27 avg=0.23\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-30500\n",
            "======== SAMPLE 1 ========\n",
            " various ideas in different situations. I think it is a waste of time to make a dog toy so that they can hurt you. \n",
            "How to build an accurate knife?:Well the hack is always to pick and choose between good and  bad things. Doctors prefer hack to ordinary knife so a choice is often all you need.From left to right:\n",
            "How can I quickly eliminate sweat/stress while in the oven?:Keeping your fridge in the house helps it to warm and be warm.I think an amazing lot of people here today had rooms completely dedicated to the room's contents. In my experience, this actually made the home warmer and more warm.  Also, a lot of the people in this picture have the same issue -- they've both.It goes without saying to stay cool!Take a shower or get your body wet during the day so you can use your clothing more efficiently. Be nice and relax. If you're doing some washings during the day, go somewhere that you can actually let the water go as you do the laundry.Holidays/nettings is not an option, if you're already doing some organizational things. If you're already doing those, I'd probably just keep you at the door during the day.You can also add/change into the list at the bottom of your list clothes. If you have a dress shirt or braille font you can also add clothes to the shopping list at the bottom of your list. In that case, the rest is out of the way at the next level.\n",
            "How can I quickly eliminate sweat/stress while in the oven?:Keep the door closed while in the oven or in the oven lamp use bags of rice and put in small pockets at the top for better circulation than before. You can try to have 5 to 10 small pockets at the bottom for more dense circulation. You can also have more space with lighter rags and more rags. It'll help better with the same things you are trying to do with your clothes right now.If you are already using a lot of rags and rented clothes that are made to last, this may be the ticket to last minute fixes the problem.\n",
            "How can I quickly eliminate sweat/stress while in the oven?:If you put your head in a toilet, it will open in hell because hold the door open while you spit in the tube. That should rescue your eyes (depressed pupils).\n",
            "How can I quickly eliminate sweat/stress while in the oven?:If you have one of those handy, you could slowly but surely open your trousers and button-down shirts in public if you don't have people there to help you. As a bonus, it would let water get out.\n",
            "How can I quickly eliminate sweat/stress while in the oven?:If you have all of your white socks, as in the office, weather forecast indicates the temperature will start going to the inside. If you have white winter pants or some other light colored pants, as in the kitchen or bathroom, weather forecast indicates the temperature will start going to the outside. If the people around you don't notice, just look around and see what else is inside.So open them.Put stuff on the ground.That's it.. gone :)\n",
            "How can I quickly eliminate sweat/stress while in the oven?:Put a cup of coffee on the stove as it lowers the oven to the oven height. Say you want to study centers (studies) about boil root cause  or reheated -- Russia and the rest of the world knows from your windows that your window needs your window. You can't do that in a room where people say newspaper is more efficient than cup.Then ask the worker to give him/hers kind of clothes for the day. Eventually the temperature of the clothing will drop and your body will adapt faster.Edit: I am not sure what the optimal window height is among many things here. Most all windows have it exactly as you do.But please don't draw attention to do here.\n",
            "How can I quickly eliminate sweat/stress while in the oven?:Just when you thought we had it dryer into a rumination, you find that you have dropped your trousers.You are painfully aware that, unbuckle their pants and heap your fist underneath as they struggle to keep their breathable you once more encounter the case of the down/down image in your mind as you slowly pull them open, fingers digging into the pants' pajamas, your head just to a side to grab the button, the shock of it happening against the grip of the button is enough to send shock through your stomach and therefore the pants.You fall into a deep sleep. Withdraw your trousers. Have a snack. Have a nice day. Goodnight.\n",
            "How can I quickly eliminate sweat/stress while in the oven?:I know this is an own temptation issue, but I came upon this like new and very effective on a daily basis.If you budget is an issue, get a bag full of mini-hacks and use them to\n",
            "\n",
            "[30510 | 8252.21] loss=0.28 avg=0.23\n",
            "[30520 | 8275.24] loss=0.21 avg=0.23\n",
            "[30530 | 8298.35] loss=0.24 avg=0.23\n",
            "[30540 | 8321.51] loss=0.27 avg=0.23\n",
            "[30550 | 8344.70] loss=0.24 avg=0.23\n",
            "[30560 | 8367.89] loss=0.21 avg=0.23\n",
            "[30570 | 8391.09] loss=0.23 avg=0.23\n",
            "[30580 | 8414.31] loss=0.22 avg=0.23\n",
            "[30590 | 8437.53] loss=0.21 avg=0.23\n",
            "[30600 | 8460.72] loss=0.14 avg=0.23\n",
            "[30610 | 8483.92] loss=0.24 avg=0.23\n",
            "[30620 | 8507.13] loss=0.17 avg=0.23\n",
            "[30630 | 8530.33] loss=0.17 avg=0.23\n",
            "[30640 | 8553.50] loss=0.27 avg=0.23\n",
            "[30650 | 8576.65] loss=0.23 avg=0.23\n",
            "[30660 | 8599.83] loss=0.29 avg=0.23\n",
            "[30670 | 8623.04] loss=0.22 avg=0.23\n",
            "[30680 | 8646.23] loss=0.25 avg=0.23\n",
            "[30690 | 8669.47] loss=0.25 avg=0.23\n",
            "[30700 | 8692.70] loss=0.23 avg=0.23\n",
            "[30710 | 8715.93] loss=0.21 avg=0.23\n",
            "[30720 | 8739.12] loss=0.25 avg=0.23\n",
            "[30730 | 8762.31] loss=0.21 avg=0.23\n",
            "[30740 | 8785.49] loss=0.24 avg=0.23\n",
            "[30750 | 8808.62] loss=0.22 avg=0.23\n",
            "[30760 | 8831.80] loss=0.17 avg=0.23\n",
            "[30770 | 8854.97] loss=0.24 avg=0.23\n",
            "[30780 | 8878.14] loss=0.16 avg=0.23\n",
            "[30790 | 8901.31] loss=0.25 avg=0.23\n",
            "[30800 | 8924.49] loss=0.21 avg=0.23\n",
            "[30810 | 8947.66] loss=0.24 avg=0.23\n",
            "[30820 | 8970.83] loss=0.21 avg=0.23\n",
            "[30830 | 8994.00] loss=0.19 avg=0.23\n",
            "[30840 | 9017.16] loss=0.17 avg=0.23\n",
            "[30850 | 9040.34] loss=0.23 avg=0.23\n",
            "[30860 | 9063.50] loss=0.20 avg=0.23\n",
            "[30870 | 9086.67] loss=0.19 avg=0.23\n",
            "[30880 | 9109.84] loss=0.20 avg=0.23\n",
            "[30890 | 9133.02] loss=0.25 avg=0.23\n",
            "[30900 | 9156.18] loss=0.18 avg=0.23\n",
            "[30910 | 9179.37] loss=0.27 avg=0.23\n",
            "[30920 | 9202.55] loss=0.23 avg=0.23\n",
            "[30930 | 9225.72] loss=0.22 avg=0.23\n",
            "[30940 | 9248.88] loss=0.19 avg=0.23\n",
            "[30950 | 9272.06] loss=0.18 avg=0.23\n",
            "[30960 | 9295.25] loss=0.21 avg=0.23\n",
            "[30970 | 9318.41] loss=0.25 avg=0.23\n",
            "[30980 | 9341.59] loss=0.22 avg=0.23\n",
            "[30990 | 9364.77] loss=0.20 avg=0.23\n",
            "[31000 | 9387.96] loss=0.24 avg=0.23\n",
            "Saving checkpoint/GPT_2_TEST_RUN_2/model-31000\n"
          ]
        }
      ],
      "source": [
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=4000,\n",
        "              restore_from='latest',\n",
        "              run_name='GPT_2_TEST_RUN_2',\n",
        "              learning_rate=1e-5,\n",
        "              print_every=10,\n",
        "              sample_every=500,\n",
        "              save_every=500\n",
        "              )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "outputs": [],
      "source": [
        "# save a copy to google drive\n",
        "gpt2.copy_checkpoint_to_gdrive(run_name='GPT_2_TEST_RUN_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "outputs": [],
      "source": [
        "# get a copy from google drive\n",
        "gpt2.copy_checkpoint_from_gdrive(run_name='GPT_2_TEST_RUN_2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fxL77nvAMAX",
        "outputId": "223a1173-9ccb-49d6-c5f4-42ba0fc5cfb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint checkpoint/GPT_2_TEST_RUN_2/model-19000\n"
          ]
        }
      ],
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='GPT_2_TEST_RUN_2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After we trained the model or loaded a retrained model from checkpoint, we can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "##the following text is from the orginal notebook about finetuning GPT-2 (last link in the credits)\n",
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DKMc0fiej4N",
        "outputId": "80f0ac6a-8b9c-43b5-b925-da536d5be9e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the cat is already out of the house (and it is), you might want to consider placing a small play area (perhaps near a small TV/phone) with your desk\n"
          ]
        }
      ],
      "source": [
        "# before running this cell make sure that the folder in checkpoint is named \"run1\".\n",
        "gpt2.generate(sess,\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              prefix=\"How can I keep my cat off my keyboard?:\",\n",
        "              include_prefix=False,\n",
        "              truncate='.',\n",
        "              nsamples=1,\n",
        "              batch_size=1\n",
        "              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce1M1hqQLxLi"
      },
      "source": [
        "##Turn the model to pytorch for uploading on huggingface."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgH51aPo1AlJ",
        "outputId": "ec14e32c-401f-4fe1-c508-97b5309b2128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3BWt64tEyq5"
      },
      "outputs": [],
      "source": [
        "!mkdir pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T1wkI4ZEleB",
        "outputId": "97a062ec-d8fa-44d9-fb6a-0aed95d5fd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting TensorFlow checkpoint from /content/checkpoint/run1\n",
            "Loading TF weight model/h0/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h0/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h0/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h0/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h0/ln_1/b with shape [768]\n",
            "Loading TF weight model/h0/ln_1/g with shape [768]\n",
            "Loading TF weight model/h0/ln_2/b with shape [768]\n",
            "Loading TF weight model/h0/ln_2/g with shape [768]\n",
            "Loading TF weight model/h0/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h0/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h1/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h1/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h1/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h1/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h1/ln_1/b with shape [768]\n",
            "Loading TF weight model/h1/ln_1/g with shape [768]\n",
            "Loading TF weight model/h1/ln_2/b with shape [768]\n",
            "Loading TF weight model/h1/ln_2/g with shape [768]\n",
            "Loading TF weight model/h1/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h1/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h10/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h10/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h10/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h10/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h10/ln_1/b with shape [768]\n",
            "Loading TF weight model/h10/ln_1/g with shape [768]\n",
            "Loading TF weight model/h10/ln_2/b with shape [768]\n",
            "Loading TF weight model/h10/ln_2/g with shape [768]\n",
            "Loading TF weight model/h10/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h10/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h11/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h11/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h11/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h11/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h11/ln_1/b with shape [768]\n",
            "Loading TF weight model/h11/ln_1/g with shape [768]\n",
            "Loading TF weight model/h11/ln_2/b with shape [768]\n",
            "Loading TF weight model/h11/ln_2/g with shape [768]\n",
            "Loading TF weight model/h11/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h11/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h2/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h2/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h2/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h2/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h2/ln_1/b with shape [768]\n",
            "Loading TF weight model/h2/ln_1/g with shape [768]\n",
            "Loading TF weight model/h2/ln_2/b with shape [768]\n",
            "Loading TF weight model/h2/ln_2/g with shape [768]\n",
            "Loading TF weight model/h2/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h2/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h3/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h3/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h3/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h3/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h3/ln_1/b with shape [768]\n",
            "Loading TF weight model/h3/ln_1/g with shape [768]\n",
            "Loading TF weight model/h3/ln_2/b with shape [768]\n",
            "Loading TF weight model/h3/ln_2/g with shape [768]\n",
            "Loading TF weight model/h3/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h3/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h4/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h4/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h4/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h4/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h4/ln_1/b with shape [768]\n",
            "Loading TF weight model/h4/ln_1/g with shape [768]\n",
            "Loading TF weight model/h4/ln_2/b with shape [768]\n",
            "Loading TF weight model/h4/ln_2/g with shape [768]\n",
            "Loading TF weight model/h4/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h4/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h5/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h5/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h5/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h5/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h5/ln_1/b with shape [768]\n",
            "Loading TF weight model/h5/ln_1/g with shape [768]\n",
            "Loading TF weight model/h5/ln_2/b with shape [768]\n",
            "Loading TF weight model/h5/ln_2/g with shape [768]\n",
            "Loading TF weight model/h5/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h5/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h6/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h6/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h6/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h6/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h6/ln_1/b with shape [768]\n",
            "Loading TF weight model/h6/ln_1/g with shape [768]\n",
            "Loading TF weight model/h6/ln_2/b with shape [768]\n",
            "Loading TF weight model/h6/ln_2/g with shape [768]\n",
            "Loading TF weight model/h6/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h6/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h7/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h7/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h7/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h7/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h7/ln_1/b with shape [768]\n",
            "Loading TF weight model/h7/ln_1/g with shape [768]\n",
            "Loading TF weight model/h7/ln_2/b with shape [768]\n",
            "Loading TF weight model/h7/ln_2/g with shape [768]\n",
            "Loading TF weight model/h7/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h7/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h8/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h8/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h8/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h8/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h8/ln_1/b with shape [768]\n",
            "Loading TF weight model/h8/ln_1/g with shape [768]\n",
            "Loading TF weight model/h8/ln_2/b with shape [768]\n",
            "Loading TF weight model/h8/ln_2/g with shape [768]\n",
            "Loading TF weight model/h8/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h8/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/h9/attn/c_attn/b with shape [2304]\n",
            "Loading TF weight model/h9/attn/c_attn/w with shape [1, 768, 2304]\n",
            "Loading TF weight model/h9/attn/c_proj/b with shape [768]\n",
            "Loading TF weight model/h9/attn/c_proj/w with shape [1, 768, 768]\n",
            "Loading TF weight model/h9/ln_1/b with shape [768]\n",
            "Loading TF weight model/h9/ln_1/g with shape [768]\n",
            "Loading TF weight model/h9/ln_2/b with shape [768]\n",
            "Loading TF weight model/h9/ln_2/g with shape [768]\n",
            "Loading TF weight model/h9/mlp/c_fc/b with shape [3072]\n",
            "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 768, 3072]\n",
            "Loading TF weight model/h9/mlp/c_proj/b with shape [768]\n",
            "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 3072, 768]\n",
            "Loading TF weight model/ln_f/b with shape [768]\n",
            "Loading TF weight model/ln_f/g with shape [768]\n",
            "Loading TF weight model/wpe with shape [1024, 768]\n",
            "Loading TF weight model/wte with shape [50257, 768]\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h0', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h0', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h0', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h0', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h0', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h0', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h1', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h1', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h1', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h1', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h1', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h1', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h10', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h10', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h10', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h10', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h10', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h10', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h11', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h11', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h11', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h11', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h11', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h11', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h2', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h2', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h2', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h2', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h2', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h2', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h3', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h3', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h3', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h3', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h3', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h3', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h4', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h4', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h4', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h4', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h4', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h4', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h5', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h5', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h5', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h5', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h5', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h5', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h6', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h6', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h6', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h6', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h6', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h6', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h7', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h7', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h7', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h7', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h7', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h7', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h8', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h8', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h8', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h8', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h8', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h8', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'b']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_attn', 'w']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h9', 'attn', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['h9', 'ln_1', 'b']\n",
            "Initialize PyTorch weight ['h9', 'ln_1', 'g']\n",
            "Initialize PyTorch weight ['h9', 'ln_2', 'b']\n",
            "Initialize PyTorch weight ['h9', 'ln_2', 'g']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'b']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_fc', 'w']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'b']\n",
            "Initialize PyTorch weight ['h9', 'mlp', 'c_proj', 'w']\n",
            "Initialize PyTorch weight ['ln_f', 'b']\n",
            "Initialize PyTorch weight ['ln_f', 'g']\n",
            "Initialize PyTorch weight ['wpe']\n",
            "Initialize PyTorch weight ['wte']\n",
            "Save PyTorch model to pytorch/pytorch_model.bin\n",
            "Save configuration file to pytorch/config.json\n"
          ]
        }
      ],
      "source": [
        "# before running this cell make sure that the folder in checkpoint is named \"run1\".\n",
        "!transformers-cli convert --model_type gpt2 --tf_checkpoint checkpoint/run1 --pytorch_dump_output pytorch --config checkpoint/run1/hparams.json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "gn2NhdYQVPvv",
        "TjIsst-_VQGG",
        "DXYoL-9mVeMN",
        "2QWwl-fWQlMx",
        "N8KXuKWzQSsN",
        "LdpZQXknFNY3",
        "pel-uBULXO2L",
        "oF4-PqF0Fl7R",
        "ce1M1hqQLxLi"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}