{
  "cells": [
    {
      "cell_type": "markdown",
      "id": 3.0293430767166755e+38,
      "metadata": {
        "id": 3.0293430767166755e+38
      },
      "source": [
        "# Gradio Demo: text_generation\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": 2.7299665331067346e+38,
      "metadata": {
        "id": 2.7299665331067346e+38,
        "outputId": "dd0b78bc-9fcb-4382-e2b7-e853a9cc6f73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.2/14.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.6/270.6 KB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.6/55.6 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 KB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gradio git+https://github.com/huggingface/transformers gradio torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "tSihU_iK9k_R"
      },
      "id": "tSihU_iK9k_R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": 2.8891853944186117e+38,
      "metadata": {
        "id": 2.8891853944186117e+38,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "3a0632a6-a10a-4967-e645-79f1859baaf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7881, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "GPT = pipeline('text-generation', model='Knows-Nothing/GPT_2_FineTuned')\n",
        "\n",
        "\n",
        "def check_if_arabic(text):\n",
        "  for ch in text:\n",
        "    if ('\\u0600' <= ch <= '\\u06FF' or\n",
        "    '\\u0750' <= ch <= '\\u077F' or\n",
        "    '\\u08A0' <= ch <= '\\u08FF' or\n",
        "    '\\uFB50' <= ch <= '\\uFDFF' or\n",
        "    '\\uFE70' <= ch <= '\\uFEFF' or\n",
        "    '\\U00010E60' <= ch <= '\\U00010E7F' or\n",
        "    '\\U0001EE00' <= ch <= '\\U0001EEFF'):\n",
        "      return True\n",
        "  return False\n",
        "\n",
        "\n",
        "def chat(message, history):\n",
        "    history = history or []\n",
        "    message = message.lower()\n",
        "    if \"name\" in message.split(' ') and \"your\" in message.split(' ') or \"ur\" in message.split(' '):\n",
        "        response = \"My name is 'Totally Not Stack Exchange'.\"\n",
        "    elif message.endswith(\"?\"):\n",
        "        response = generate(message)\n",
        "    elif \"who\" in message.split(' ') and \"made\" in message.split(' ') or \"created\" in message.split(' '):\n",
        "        response = \"Gehan Sherif and Omar Emad Created Me.\"\n",
        "    elif \"why\" in message.split(' ') and \"made\" in message.split(' ') or \"created\" in message.split(' '):\n",
        "        response = \"Sigh, I was created as the final NLP project in CIE 553.\"\n",
        "    elif (\"good\" in message.split(' ') or \"fine\" in message.split(' ')) and (\"iam\" in message.split(' ') or \"am\" in message.split(' ')) or (\"good\" in message.split(' ') or \"fine\" in message.split(' ')):\n",
        "        response = \"Thats nice to hear!\"\n",
        "    elif \"hey\" in message.split(' ') or \"hi\" in message.split(' ')or \"yo\" in message.split(' '):\n",
        "        response = \"Hey, how are you?\"\n",
        "    elif check_if_arabic(message):\n",
        "        response = \"بقولك ايه يا شبح اتكلم انجليزي انا من ايجيبت متتعبنيش معاك\"\n",
        "    else:\n",
        "        response = \"I don't know.\"\n",
        "    history.append((message, response))\n",
        "    return history, history\n",
        "\n",
        "def generate(text):\n",
        "    text+=':'\n",
        "    result = GPT(text,\n",
        "                  max_length=50,\n",
        "                  num_return_sequences=1,\n",
        "                  temperature=0.7,\n",
        "                  top_k=200,\n",
        "                  top_p=0.85,\n",
        "                  repetition_penalty = 1.5,\n",
        "                  no_repeat_ngram_size = 5,\n",
        "                 )\n",
        "    return result[0]['generated_text'].split(':')[1].split('.')[0]+\".\"\n",
        "\n",
        "#Custom css for components\n",
        "baseCss = '{width: fit-content; height: 505px; align-self: center;}'\n",
        "botCss =  '{width: 505px; height: 400px;} .h-\\[40vh\\] {height:80vh;}'\n",
        "txtCss =  '{width: 505px;}'\n",
        "btnCss =  '{color: orange; width: 505px;}'\n",
        "myCss =   \"#row {} #btn {} #bot {} #txtbox {}\".format(baseCss, btnCss, botCss, txtCss)\n",
        "\n",
        "with gr.Blocks(css=myCss) as demo:\n",
        "  with gr.Row(elem_id=\"row\"):\n",
        "    with gr.Column():\n",
        "      chatbot = gr.Chatbot(elem_id=\"bot\").style(color_map=(\"green\", \"blue\"))\n",
        "      msg = gr.Textbox(placeholder=\"hey\", label=\"Talk To Totally Not Stack Exchange, to ask a question about life hacks end it with a '?'.\", elem_id=\"txtbox\")\n",
        "      Send_Btn = gr.Button(\"Send\", elem_id=\"btn\")\n",
        "      Send_Btn.click(chat, inputs=[msg,chatbot], outputs=[chatbot,chatbot])\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}